<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Your future depends on your dreams">
    <meta name="keyword" content="小炒肉, 运维工程师, Jicki, DevOps, Docker, Kubernetes">
    <link rel="shortcut icon" href="/img/ironman-draw.png">
    <!-- Place this tag in your head or just before your close body tag. -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <title>
        
          小炒肉 | Blog
        
    </title>

    <link rel="canonical" href="https://www.jicki.me/2019/01/30/2018-12-19-kubernetes-1.13.1/">

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="/css/bootstrap.min.css">

    <!-- Custom CSS --> 
    <link rel="stylesheet" href="/css/beantech.min.css">

    <link rel="stylesheet" href="/css/donate.css">
    
    <!-- Pygments Highlight CSS -->
    <link rel="stylesheet" href="/css/highlight.css">

    <link rel="stylesheet" href="/css/widget.css">

    <link rel="stylesheet" href="/css/rocket.css">

    <link rel="stylesheet" href="/css/signature.css">

    <link rel="stylesheet" href="/css/toc.css">

    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">


    <!-- Hux Delete, sad but pending in China
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/
    css'>
    -->


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
</head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">
	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            background-image: url('/img/article_header/article_bg.jpg')
            /*post*/
        
    }
    
</style>

<header class="intro-header">
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                        </div>
                        <h1></h1>
                        <h2 class="subheading"></h2>
                        <span class="meta">
                            Posted by 小炒肉 on
                            2019-01-30
                        </span>
                    </div>
                


                </div>
            </div>
        </div>
    </div>
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">小炒肉</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/about/">About</a>
                        </li>
                        
                    

                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Modify by Yu-Hsuan Yen -->

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <hr>
<p>layout: post<br>
title: kubernetes 1.13.1<br>
categories: kubernetes<br>
description: kubernetes 1.13.1<br>
keywords: kubernetes<br>
feature-img: assets/img/pexels/desk-top.jpeg<br>
catalog: true<br>
tags:</p>
<ul>
<li>kubernetes</li>
<li>docker</li>
</ul>
<hr>
<blockquote>
<p>Update kubernetes 1.13.1</p>
</blockquote>
<h1><span id="changelog">CHANGELOG</span></h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">0. 创建 deploymoent DaemonSet 的apiVersion: extensions/v1beta1 </span><br><span class="line">    更新为 apiVersion: apps/v1, 否则日志抛出错误:</span><br><span class="line">        watch of *v1beta1.Event ended with: The resourceVersion for the provided watch is too old.</span><br><span class="line"></span><br><span class="line">1. 更新一个 CVE-2018-1002105 安全问题，必须更新(v1.10.11，v1.11.5和v1.12.3)子版本更新</span><br><span class="line"></span><br><span class="line">2. etcd 版本 更新为 v3.2.24 , 删除 etcd v2 支持, kube-apiserver 配置 --storage-backend=etcd3</span><br><span class="line"></span><br><span class="line">3. kube-apiserver 中 标签:  </span><br><span class="line">    --service-account-api-audiences 更改为 --api-audiences</span><br><span class="line">    --experimental-encryption-provider-config 更改为 --encryption-provider-config</span><br><span class="line">    </span><br><span class="line">    --encryption-provider-config 标签引用的配置文件中:</span><br><span class="line">        kind: EncryptionConfig 更改为 kind: EncryptionConfiguration</span><br><span class="line">        apiVersion: v1 更改为 apiVersion: apiserver.config.k8s.io/v1</span><br></pre></td></tr></table></figure>
<h1><span id="kubernetes-1131">kubernetes 1.13.1</span></h1>
<h2><span id="环境说明">环境说明</span></h2>
<blockquote>
<p>基于 二进制 文件部署<br>
本地化 kube-apiserver, kube-controller-manager , kube-scheduler<br>
我这边配置  既是 master 也是 nodes</p>
</blockquote>
<blockquote>
<p>这里配置2个Master  1个node,   Master-64 只做 Master,  Master-65 既是 Master 也是 Node,  node-66 只做单纯 Node</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubernetes-64: 172.16.1.64</span><br><span class="line">kubernetes-65: 172.16.1.65</span><br><span class="line">kubernetes-66: 172.16.1.66</span><br></pre></td></tr></table></figure>
<h2><span id="初始化环境">初始化环境</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl --static set-hostname hostname</span><br><span class="line"></span><br><span class="line">kubernetes-64: 172.16.1.64</span><br><span class="line">kubernetes-65: 172.16.1.65</span><br><span class="line">kubernetes-66: 172.16.1.66</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">#编辑 /etc/hosts 文件，配置hostname 通信</span><br><span class="line"></span><br><span class="line">vi /etc/hosts</span><br><span class="line"></span><br><span class="line">172.16.1.64  kubernetes-64</span><br><span class="line">172.16.1.65  kubernetes-65</span><br><span class="line">172.16.1.66  kubernetes-66</span><br></pre></td></tr></table></figure>
<h1><span id="创建-验证">创建 验证</span></h1>
<blockquote>
<p>这里使用 CloudFlare 的 PKI 工具集 cfssl 来生成 Certificate Authority (CA) 证书和秘钥文件。</p>
</blockquote>
<h2><span id="安装-cfssl">安装 cfssl</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /opt/local/cfssl</span><br><span class="line"></span><br><span class="line">cd /opt/local/cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">mv cfssl_linux-amd64 cfssl</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">mv cfssljson_linux-amd64 cfssljson</span><br><span class="line"></span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64</span><br><span class="line">mv cfssl-certinfo_linux-amd64 cfssl-certinfo</span><br><span class="line"></span><br><span class="line">chmod +x *</span><br></pre></td></tr></table></figure>
<h2><span id="创建-ca-证书配置">创建 CA 证书配置</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir /opt/ssl</span><br><span class="line"></span><br><span class="line">cd /opt/ssl</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"># config.json 文件</span><br><span class="line"></span><br><span class="line">vi  config.json</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;signing&quot;: &#123;</span><br><span class="line">    &quot;default&quot;: &#123;</span><br><span class="line">      &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">    &#125;,</span><br><span class="line">    &quot;profiles&quot;: &#123;</span><br><span class="line">      &quot;kubernetes&quot;: &#123;</span><br><span class="line">        &quot;usages&quot;: [</span><br><span class="line">            &quot;signing&quot;,</span><br><span class="line">            &quot;key encipherment&quot;,</span><br><span class="line">            &quot;server auth&quot;,</span><br><span class="line">            &quot;client auth&quot;</span><br><span class="line">        ],</span><br><span class="line">        &quot;expiry&quot;: &quot;87600h&quot;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># csr.json 文件</span><br><span class="line"></span><br><span class="line">vi csr.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;kubernetes&quot;,</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;ShenZhen&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;ShenZhen&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2><span id="生成-ca-证书和私钥">生成 CA 证书和私钥</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">cd /opt/ssl/</span><br><span class="line"></span><br><span class="line">/opt/local/cfssl/cfssl gencert -initca csr.json | \</span><br><span class="line">/opt/local/cfssl/cfssljson -bare ca</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@kubernetes-64 ssl]# ls -lt</span><br><span class="line">总用量 20</span><br><span class="line">-rw-r--r-- 1 root root 1005 7月   3 17:26 ca.csr</span><br><span class="line">-rw------- 1 root root 1675 7月   3 17:26 ca-key.pem</span><br><span class="line">-rw-r--r-- 1 root root 1363 7月   3 17:26 ca.pem</span><br><span class="line">-rw-r--r-- 1 root root  210 7月   3 17:24 csr.json</span><br><span class="line">-rw-r--r-- 1 root root  292 7月   3 17:23 config.json</span><br></pre></td></tr></table></figure>
<h2><span id="分发证书">分发证书</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 创建证书目录</span><br><span class="line">mkdir -p /etc/kubernetes/ssl</span><br><span class="line"></span><br><span class="line"># 拷贝所有文件到目录下</span><br><span class="line">cp *.pem /etc/kubernetes/ssl</span><br><span class="line">cp ca.csr /etc/kubernetes/ssl</span><br><span class="line"></span><br><span class="line"># 这里要将文件拷贝到所有的k8s 机器上</span><br><span class="line"></span><br><span class="line">scp *.pem *.csr 172.16.1.65:/etc/kubernetes/ssl/</span><br><span class="line"></span><br><span class="line">scp *.pem *.csr 172.16.1.66:/etc/kubernetes/ssl/</span><br></pre></td></tr></table></figure>
<h1><span id="安装-docker">安装 docker</span></h1>
<blockquote>
<p>官方最新版本 docker 为 18.06.1 , 官方验证最高版本支持到 18.06.0</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"># 导入 yum 源</span><br><span class="line"></span><br><span class="line"># 安装 yum-config-manager</span><br><span class="line"></span><br><span class="line">yum -y install yum-utils</span><br><span class="line"></span><br><span class="line"># 导入</span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https://download.docker.com/linux/centos/docker-ce.repo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 更新 repo</span><br><span class="line">yum makecache</span><br><span class="line"></span><br><span class="line"># 查看yum 版本</span><br><span class="line"></span><br><span class="line">yum list docker-ce.x86_64  --showduplicates |sort -r</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 安装指定版本 docker-ce 18.06 被 docker-ce-selinux 依赖</span><br><span class="line"># 不能直接yum 安装 docker-ce-selinux</span><br><span class="line"></span><br><span class="line">wget https://download.docker.com/linux/centos/7/x86_64/stable/\</span><br><span class="line">Packages/docker-ce-18.06.0.ce-3.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">rpm -ivh docker-ce-18.06.0.ce-3.el7.x86_64.rpm</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">yum -y install docker-ce-18.06.0.ce</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 查看安装</span><br><span class="line"></span><br><span class="line">docker version</span><br><span class="line">Client:</span><br><span class="line"> Version:           18.06.0-ce</span><br><span class="line"> API version:       1.38</span><br><span class="line"> Go version:        go1.10.3</span><br><span class="line"> Git commit:        0ffa825</span><br><span class="line"> Built:             Wed Jul 18 19:08:18 2018</span><br><span class="line"> OS/Arch:           linux/amd64</span><br></pre></td></tr></table></figure>
<h2><span id="更改docker-配置">更改docker 配置</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"># 添加配置</span><br><span class="line"></span><br><span class="line">vi /etc/systemd/system/docker.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Docker Application Container Engine</span><br><span class="line">Documentation=http://docs.docker.com</span><br><span class="line">After=network.target docker-storage-setup.service</span><br><span class="line">Wants=docker-storage-setup.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">Environment=GOTRACEBACK=crash</span><br><span class="line">ExecReload=/bin/kill -s HUP $MAINPID</span><br><span class="line">Delegate=yes</span><br><span class="line">KillMode=process</span><br><span class="line">ExecStart=/usr/bin/dockerd \</span><br><span class="line">          $DOCKER_OPTS \</span><br><span class="line">          $DOCKER_STORAGE_OPTIONS \</span><br><span class="line">          $DOCKER_NETWORK_OPTIONS \</span><br><span class="line">          $DOCKER_DNS_OPTIONS \</span><br><span class="line">          $INSECURE_REGISTRY</span><br><span class="line">LimitNOFILE=1048576</span><br><span class="line">LimitNPROC=1048576</span><br><span class="line">LimitCORE=infinity</span><br><span class="line">TimeoutStartSec=1min</span><br><span class="line">Restart=on-abnormal</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"># 修改其他配置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 低版本内核， kernel 3.10.x  配置使用 overlay2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi /etc/docker/daemon.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;storage-driver&quot;: &quot;overlay2&quot;,</span><br><span class="line">  &quot;storage-opts&quot;: [</span><br><span class="line">    &quot;overlay2.override_kernel_check=true&quot;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mkdir -p /etc/systemd/system/docker.service.d/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi /etc/systemd/system/docker.service.d/docker-options.conf</span><br><span class="line"></span><br><span class="line"># 添加如下 :   (注意 environment 必须在同一行，如果出现换行会无法加载)</span><br><span class="line"></span><br><span class="line"># docker 版本 17.03.2 之前配置为 --graph=/opt/docker</span><br><span class="line"></span><br><span class="line"># docker 版本 17.04.x 之后配置为 --data-root=/opt/docker </span><br><span class="line"> </span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;DOCKER_OPTS=--insecure-registry=10.254.0.0/16 \</span><br><span class="line">    --registry-mirror=http://b438f72b.m.daocloud.io \</span><br><span class="line">    --data-root=/opt/docker --log-opt max-size=50m --log-opt max-file=5&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi /etc/systemd/system/docker.service.d/docker-dns.conf</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 添加如下 : </span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Environment=&quot;DOCKER_DNS_OPTIONS=\</span><br><span class="line">    --dns 10.254.0.2 --dns 114.114.114.114 \</span><br><span class="line">    --dns-search default.svc.cluster.local \</span><br><span class="line">    --dns-search svc.cluster.local \</span><br><span class="line">    --dns-opt ndots:2 --dns-opt timeout:2 --dns-opt attempts:2&quot;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 重新读取配置，启动 docker </span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start docker</span><br><span class="line">systemctl enable docker</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 如果报错 请使用</span><br><span class="line">journalctl -f -t docker  和 journalctl -u docker 来定位问题</span><br></pre></td></tr></table></figure>
<h1><span id="etcd-集群">etcd 集群</span></h1>
<blockquote>
<p>etcd 是k8s集群最重要的组件， etcd 挂了，集群就挂了， 1.13.1 etcd 支持最新版本为 v3.2.24</p>
</blockquote>
<h2><span id="安装-etcd">安装 etcd</span></h2>
<blockquote>
<p>官方地址 <a href="https://github.com/coreos/etcd/releases" target="_blank" rel="noopener">https://github.com/coreos/etcd/releases</a></p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 下载 二进制文件</span><br><span class="line"></span><br><span class="line">wget https://github.com/coreos/etcd/releases/download/v3.2.24/\</span><br><span class="line">etcd-v3.2.24-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">tar zxvf etcd-v3.2.24-linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line">cd etcd-v3.2.24-linux-amd64</span><br><span class="line"></span><br><span class="line">mv etcd  etcdctl /usr/bin/</span><br></pre></td></tr></table></figure>
<h2><span id="创建-etcd-证书">创建 etcd 证书</span></h2>
<blockquote>
<p>etcd 证书这里，默认配置三个，后续如果需要增加，更多的 etcd 节点<br>
这里的认证IP 请多预留几个，以备后续添加能通过认证，不需要重新签发</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/ssl/</span><br><span class="line"></span><br><span class="line">vi etcd-csr.json</span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">  &quot;CN&quot;: &quot;etcd&quot;,</span><br><span class="line">  &quot;hosts&quot;: [</span><br><span class="line">    &quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;172.16.1.64&quot;,</span><br><span class="line">    &quot;172.16.1.65&quot;,</span><br><span class="line">    &quot;172.16.1.66&quot;</span><br><span class="line">  ],</span><br><span class="line">  &quot;key&quot;: &#123;</span><br><span class="line">    &quot;algo&quot;: &quot;rsa&quot;,</span><br><span class="line">    &quot;size&quot;: 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;names&quot;: [</span><br><span class="line">    &#123;</span><br><span class="line">      &quot;C&quot;: &quot;CN&quot;,</span><br><span class="line">      &quot;ST&quot;: &quot;ShenZhen&quot;,</span><br><span class="line">      &quot;L&quot;: &quot;ShenZhen&quot;,</span><br><span class="line">      &quot;O&quot;: &quot;k8s&quot;,</span><br><span class="line">      &quot;OU&quot;: &quot;System&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 生成 etcd   密钥</span><br><span class="line"></span><br><span class="line">/opt/local/cfssl/cfssl gencert -ca=/opt/ssl/ca.pem \</span><br><span class="line">  -ca-key=/opt/ssl/ca-key.pem \</span><br><span class="line">  -config=/opt/ssl/config.json \</span><br><span class="line">  -profile=kubernetes etcd-csr.json | \</span><br><span class="line">  /opt/local/cfssl/cfssljson -bare etcd</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"># 查看生成</span><br><span class="line"></span><br><span class="line">[root@kubernetes-64 ssl]# ls etcd*</span><br><span class="line">etcd.csr  etcd-csr.json  etcd-key.pem  etcd.pem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 检查证书</span><br><span class="line"></span><br><span class="line">[root@kubernetes-64 ssl]# /opt/local/cfssl/cfssl-certinfo -cert etcd.pem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 拷贝到etcd服务器</span><br><span class="line"></span><br><span class="line"># etcd-1 </span><br><span class="line">cp etcd*.pem /etc/kubernetes/ssl/</span><br><span class="line"></span><br><span class="line"># etcd-2</span><br><span class="line">scp etcd*.pem 172.16.1.65:/etc/kubernetes/ssl/</span><br><span class="line"></span><br><span class="line"># etcd-3</span><br><span class="line">scp etcd*.pem 172.16.1.66:/etc/kubernetes/ssl/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 如果 etcd 非 root 用户，读取证书会提示没权限</span><br><span class="line"></span><br><span class="line">chmod 644 /etc/kubernetes/ssl/etcd-key.pem</span><br></pre></td></tr></table></figure>
<h2><span id="修改-etcd-配置">修改 etcd 配置</span></h2>
<blockquote>
<p>由于 etcd 是最重要的组件，所以 --data-dir 请配置到其他路径中</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 创建 etcd data 目录， 并授权</span><br><span class="line"></span><br><span class="line">useradd etcd</span><br><span class="line"></span><br><span class="line">mkdir -p /opt/etcd</span><br><span class="line"></span><br><span class="line">chown -R etcd:etcd /opt/etcd</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># etcd-1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">vi /etc/systemd/system/etcd.service</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Server</span><br><span class="line">After=network.target</span><br><span class="line">After=network-online.target</span><br><span class="line">Wants=network-online.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">Type=notify</span><br><span class="line">WorkingDirectory=/opt/etcd/</span><br><span class="line">User=etcd</span><br><span class="line"># set GOMAXPROCS to number of processors</span><br><span class="line">ExecStart=/usr/bin/etcd \</span><br><span class="line">  --name=etcd1 \</span><br><span class="line">  --cert-file=/etc/kubernetes/ssl/etcd.pem \</span><br><span class="line">  --key-file=/etc/kubernetes/ssl/etcd-key.pem \</span><br><span class="line">  --peer-cert-file=/etc/kubernetes/ssl/etcd.pem \</span><br><span class="line">  --peer-key-file=/etc/kubernetes/ssl/etcd-key.pem \</span><br><span class="line">  --trusted-ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem \</span><br><span class="line">  --initial-advertise-peer-urls=https://172.16.1.64:2380 \</span><br><span class="line">  --listen-peer-urls=https://172.16.1.64:2380 \</span><br><span class="line">  --listen-client-urls=https://172.16.1.64:2379,http://127.0.0.1:2379 \</span><br><span class="line">  --advertise-client-urls=https://172.16.1.64:2379 \</span><br><span class="line">  --initial-cluster-token=k8s-etcd-cluster \</span><br><span class="line">  --initial-cluster=etcd1=https://172.16.1.64:2380,etcd2=https://172.16.1.65:2380,etcd3=https://172.16.1.66:2380 \</span><br><span class="line">  --initial-cluster-state=new \</span><br><span class="line">  --data-dir=/opt/etcd/</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=5</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line"></span><br><span class="line">```</span><br></pre></td></tr></table></figure>
<h1><span id="etcd-2">etcd-2</span></h1>
<p>vi /etc/systemd/system/etcd.service</p>
<p>[Unit]<br>
Description=Etcd Server<br>
After=network.target<br>
After=network-online.target<br>
Wants=network-online.target</p>
<p>[Service]<br>
Type=notify<br>
WorkingDirectory=/opt/etcd/<br>
User=etcd</p>
<h1><span id="set-gomaxprocs-to-number-of-processors">set GOMAXPROCS to number of processors</span></h1>
<p>ExecStart=/usr/bin/etcd <br>
–name=etcd2 <br>
–cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
–peer-cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–peer-key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
–trusted-ca-file=/etc/kubernetes/ssl/ca.pem <br>
–peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem <br>
–initial-advertise-peer-urls=https://172.16.1.65:2380 <br>
–listen-peer-urls=https://172.16.1.65:2380 <br>
–listen-client-urls=https://172.16.1.65:2379,<a href="http://127.0.0.1:2379" target="_blank" rel="noopener">http://127.0.0.1:2379</a> <br>
–advertise-client-urls=https://172.16.1.65:2379 <br>
–initial-cluster-token=k8s-etcd-cluster <br>
–initial-cluster=etcd1=https://172.16.1.64:2380,etcd2=https://172.16.1.65:2380,etcd3=https://172.16.1.66:2380 <br>
–initial-cluster-state=new <br>
–data-dir=/opt/etcd<br>
Restart=on-failure<br>
RestartSec=5<br>
LimitNOFILE=65536</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="etcd-3">etcd-3</span></h1>
<p>vi /etc/systemd/system/etcd.service</p>
<p>[Unit]<br>
Description=Etcd Server<br>
After=network.target<br>
After=network-online.target<br>
Wants=network-online.target</p>
<p>[Service]<br>
Type=notify<br>
WorkingDirectory=/opt/etcd/<br>
User=etcd</p>
<h1><span id="set-gomaxprocs-to-number-of-processors">set GOMAXPROCS to number of processors</span></h1>
<p>ExecStart=/usr/bin/etcd <br>
–name=etcd3 <br>
–cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
–peer-cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–peer-key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
–trusted-ca-file=/etc/kubernetes/ssl/ca.pem <br>
–peer-trusted-ca-file=/etc/kubernetes/ssl/ca.pem <br>
–initial-advertise-peer-urls=https://172.16.1.66:2380 <br>
–listen-peer-urls=https://172.16.1.66:2380 <br>
–listen-client-urls=https://172.16.1.66:2379,<a href="http://127.0.0.1:2379" target="_blank" rel="noopener">http://127.0.0.1:2379</a> <br>
–advertise-client-urls=https://172.16.1.66:2379 <br>
–initial-cluster-token=k8s-etcd-cluster <br>
–initial-cluster=etcd1=https://172.16.1.64:2380,etcd2=https://172.16.1.65:2380,etcd3=https://172.16.1.66:2380 <br>
–initial-cluster-state=new <br>
–data-dir=/opt/etcd/<br>
Restart=on-failure<br>
RestartSec=5<br>
LimitNOFILE=65536</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 启动 etcd</span><br><span class="line"></span><br><span class="line">&gt; 分别启动 所有节点的 etcd 服务</span><br></pre></td></tr></table></figure>
<p>systemctl daemon-reload<br>
systemctl enable etcd<br>
systemctl start etcd<br>
systemctl status etcd</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t etcd  和 journalctl -u etcd 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 验证 etcd 集群状态</span><br><span class="line"></span><br><span class="line">&gt; 查看 etcd 集群状态：</span><br></pre></td></tr></table></figure>
<p>etcdctl --endpoints=https://172.16.1.64:2379,<a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a>,<a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a><br>
–cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–ca-file=/etc/kubernetes/ssl/ca.pem <br>
–key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
cluster-health</p>
<p>member 35eefb8e7cc93b53 is healthy: got healthy result from <a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a><br>
member 4576ff5ed626a66b is healthy: got healthy result from <a href="https://172.16.1.64:2379" target="_blank" rel="noopener">https://172.16.1.64:2379</a><br>
member bf3bd651ec832339 is healthy: got healthy result from <a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a><br>
cluster is healthy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 查看 etcd 集群成员：</span><br></pre></td></tr></table></figure>
<p>etcdctl --endpoints=https://172.16.1.64:2379,<a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a>,<a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a><br>
–cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–ca-file=/etc/kubernetes/ssl/ca.pem <br>
–key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
member list</p>
<p>35eefb8e7cc93b53: name=etcd3 peerURLs=https://172.16.1.66:2380 clientURLs=https://172.16.1.66:2379 isLeader=false<br>
4576ff5ed626a66b: name=etcd1 peerURLs=https://172.16.1.64:2380 clientURLs=https://172.16.1.64:2379 isLeader=true<br>
bf3bd651ec832339: name=etcd2 peerURLs=https://172.16.1.65:2380 clientURLs=https://172.16.1.65:2379 isLeader=false</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 配置 Kubernetes 集群</span><br><span class="line"></span><br><span class="line">&gt; kubectl 安装在所有需要进行操作的机器上</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## Master and Node</span><br><span class="line"></span><br><span class="line">&gt; Master 需要部署 kube-apiserver , kube-scheduler , kube-controller-manager 这三个组件。</span><br><span class="line">kube-scheduler 作用是调度pods分配到那个node里，简单来说就是资源调度。</span><br><span class="line">&gt;</span><br><span class="line">kube-controller-manager 作用是 对 deployment controller , replication controller, endpoints controller, namespace controller, and serviceaccounts controller等等的循环控制，与kube-apiserver交互。</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 安装组件</span><br></pre></td></tr></table></figure>
<h1><span id="从github-上下载版本">从github 上下载版本</span></h1>
<p>cd /tmp</p>
<p>wget <a href="https://dl.k8s.io/v1.13.1/kubernetes-server-linux-amd64.tar.gz" target="_blank" rel="noopener">https://dl.k8s.io/v1.13.1/kubernetes-server-linux-amd64.tar.gz</a></p>
<p>tar -xzvf kubernetes-server-linux-amd64.tar.gz</p>
<p>cd kubernetes</p>
<p>cp -r server/bin/{kube-apiserver,kube-controller-manager,kube-scheduler,kubectl,kubelet,kubeadm} /usr/local/bin/</p>
<p>scp server/bin/{kube-apiserver,kube-controller-manager,kube-scheduler,kubectl,kube-proxy,kubelet,kubeadm} 172.16.1.65:/usr/local/bin/</p>
<p>scp server/bin/{kube-proxy,kubelet} 172.16.1.66:/usr/local/bin/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 admin 证书</span><br><span class="line"></span><br><span class="line">&gt; kubectl 与 kube-apiserver 的安全端口通信，需要为安全通信提供 TLS 证书和秘钥。</span><br></pre></td></tr></table></figure>
<p>cd /opt/ssl/</p>
<p>vi admin-csr.json</p>
<p>{<br>
“CN”: “admin”,<br>
“hosts”: [],<br>
“key”: {<br>
“algo”: “rsa”,<br>
“size”: 2048<br>
},<br>
“names”: [<br>
{<br>
“C”: “CN”,<br>
“ST”: “ShenZhen”,<br>
“L”: “ShenZhen”,<br>
“O”: “system:masters”,<br>
“OU”: “System”<br>
}<br>
]<br>
}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="生成-admin-证书和私钥">生成 admin 证书和私钥</span></h1>
<p>cd /opt/ssl/</p>
<p>/opt/local/cfssl/cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem <br>
-ca-key=/etc/kubernetes/ssl/ca-key.pem <br>
-config=/opt/ssl/config.json <br>
-profile=kubernetes admin-csr.json | /opt/local/cfssl/cfssljson -bare admin</p>
<h1><span id="查看生成">查看生成</span></h1>
<p>[root@kubernetes-64 ssl]# ls admin*<br>
admin.csr  admin-csr.json  admin-key.pem  admin.pem</p>
<p>cp admin*.pem /etc/kubernetes/ssl/</p>
<p>scp admin*.pem 172.16.1.65:/etc/kubernetes/ssl/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 生成 kubernetes 配置文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt;  生成证书相关的配置文件存储与 /root/.kube 目录中</span><br></pre></td></tr></table></figure>
<h1><span id="配置-kubernetes-集群">配置 kubernetes 集群</span></h1>
<p>kubectl config set-cluster kubernetes <br>
–certificate-authority=/etc/kubernetes/ssl/ca.pem <br>
–embed-certs=true <br>
–server=https://127.0.0.1:6443</p>
<h1><span id="配置-客户端认证">配置 客户端认证</span></h1>
<p>kubectl config set-credentials admin <br>
–client-certificate=/etc/kubernetes/ssl/admin.pem <br>
–embed-certs=true <br>
–client-key=/etc/kubernetes/ssl/admin-key.pem</p>
<p>kubectl config set-context kubernetes <br>
–cluster=kubernetes <br>
–user=admin</p>
<p>kubectl config use-context kubernetes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 kubernetes 证书</span><br></pre></td></tr></table></figure>
<p>cd /opt/ssl</p>
<p>vi kubernetes-csr.json</p>
<p>{<br>
“CN”: “kubernetes”,<br>
“hosts”: [<br>
“127.0.0.1”,<br>
“172.16.1.64”,<br>
“172.16.1.65”,<br>
“172.16.1.66”,<br>
“10.254.0.1”,<br>
“kubernetes”,<br>
“kubernetes.default”,<br>
“kubernetes.default.svc”,<br>
“kubernetes.default.svc.cluster”,<br>
“kubernetes.default.svc.cluster.local”<br>
],<br>
“key”: {<br>
“algo”: “rsa”,<br>
“size”: 2048<br>
},<br>
“names”: [<br>
{<br>
“C”: “CN”,<br>
“ST”: “ShenZhen”,<br>
“L”: “ShenZhen”,<br>
“O”: “k8s”,<br>
“OU”: “System”<br>
}<br>
]<br>
}</p>
<h2><span id="这里-hosts-字段中-三个-ip-分别为-127001-本机-17216164-和-17216165-为-master-的ip多个master需要写多个-1025401-为-kubernetes-svc-的-ip-一般是-部署网络的第一个ip-如-1025401-在启动完成后我们使用-kubectl-get-svc-就可以查看到">这里 hosts 字段中 三个 IP 分别为 127.0.0.1 本机， 172.16.1.64 和 172.16.1.65 为 Master 的IP，多个Master需要写多个。  10.254.0.1 为 kubernetes SVC 的 IP， 一般是 部署网络的第一个IP , 如: 10.254.0.1 ， 在启动完成后，我们使用   kubectl get svc ， 就可以查看到</span></h2>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 生成 kubernetes 证书和私钥</span><br></pre></td></tr></table></figure>
<p>/opt/local/cfssl/cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem <br>
-ca-key=/etc/kubernetes/ssl/ca-key.pem <br>
-config=/opt/ssl/config.json <br>
-profile=kubernetes kubernetes-csr.json | /opt/local/cfssl/cfssljson -bare kubernetes</p>
<h1><span id="查看生成">查看生成</span></h1>
<p>[root@kubernetes-64 ssl]# ls -lt kubernetes*<br>
-rw-r–r-- 1 root root 1261 11月 16 15:12 kubernetes.csr<br>
-rw------- 1 root root 1679 11月 16 15:12 kubernetes-key.pem<br>
-rw-r–r-- 1 root root 1635 11月 16 15:12 kubernetes.pem<br>
-rw-r–r-- 1 root root  475 11月 16 15:12 kubernetes-csr.json</p>
<h1><span id="拷贝到目录">拷贝到目录</span></h1>
<p>cp kubernetes*.pem /etc/kubernetes/ssl/</p>
<p>scp kubernetes*.pem 172.16.1.65:/etc/kubernetes/ssl/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 配置 kube-apiserver</span><br><span class="line"></span><br><span class="line">&gt; kubelet 首次启动时向 kube-apiserver 发送 TLS Bootstrapping 请求，kube-apiserver 验证 kubelet 请求中的 token 是否与它配置的 token  一致，如果一致则自动为 kubelet生成证书和秘钥。</span><br></pre></td></tr></table></figure>
<h1><span id="生成-token">生成 token</span></h1>
<p>[root@kubernetes-64 ssl]# head -c 16 /dev/urandom | od -An -t x | tr -d ’ '<br>
22a762c6fd1e636c3b1c7248980e4b93</p>
<h1><span id="创建-encryption-configyaml-配置">创建 encryption-config.yaml 配置</span></h1>
<p>cat &gt; encryption-config.yaml &lt;&lt;EOF<br>
kind: EncryptionConfiguration<br>
apiVersion: <a href="http://apiserver.config.k8s.io/v1" target="_blank" rel="noopener">apiserver.config.k8s.io/v1</a><br>
resources:</p>
<ul>
<li>resources:
<ul>
<li>secrets<br>
providers:</li>
<li>aescbc:<br>
keys:<br>
- name: key1<br>
secret: 40179b02a8f6da07d90392ae966f7749</li>
<li>identity: {}<br>
EOF</li>
</ul>
</li>
</ul>
<h1><span id="拷贝">拷贝</span></h1>
<p>cp encryption-config.yaml /etc/kubernetes/</p>
<p>scp encryption-config.yaml 172.16.1.65:/etc/kubernetes/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="生成高级审核配置文件">生成高级审核配置文件</span></h1>
<blockquote>
<p>官方说明 <a href="https://kubernetes.io/docs/tasks/debug-application-cluster/audit/" target="_blank" rel="noopener">https://kubernetes.io/docs/tasks/debug-application-cluster/audit/</a></p>
<p>如下为最低限度的日志审核</p>
</blockquote>
<p>cd /etc/kubernetes</p>
<p>cat &gt;&gt; audit-policy.yaml &lt;&lt;EOF</p>
<h1><span id="log-all-requests-at-the-metadata-level">Log all requests at the Metadata level.</span></h1>
<p>apiVersion: <a href="http://audit.k8s.io/v1" target="_blank" rel="noopener">audit.k8s.io/v1</a><br>
kind: Policy<br>
rules:</p>
<ul>
<li>level: Metadata<br>
EOF</li>
</ul>
<h1><span id="拷贝">拷贝</span></h1>
<p>scp audit-policy.yaml 172.16.1.65:/etc/kubernetes/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 kube-apiserver.service 文件</span><br></pre></td></tr></table></figure>
<h1><span id="自定义-系统-service-文件一般存于-etcsystemdsystem-下">自定义 系统 service 文件一般存于 /etc/systemd/system/ 下</span></h1>
<h1><span id="配置为-各自的本地-ip">配置为 各自的本地 IP</span></h1>
<p>vi /etc/systemd/system/kube-apiserver.service</p>
<p>[Unit]<br>
Description=Kubernetes API Server<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes<br>
After=network.target</p>
<p>[Service]<br>
User=root<br>
ExecStart=/usr/local/bin/kube-apiserver <br>
–admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota,NodeRestriction <br>
–anonymous-auth=false <br>
–encryption-provider-config=/etc/kubernetes/encryption-config.yaml <br>
–advertise-address=172.16.1.64 <br>
–allow-privileged=true <br>
–apiserver-count=3 <br>
–audit-policy-file=/etc/kubernetes/audit-policy.yaml <br>
–audit-log-maxage=30 <br>
–audit-log-maxbackup=3 <br>
–audit-log-maxsize=100 <br>
–audit-log-path=/var/log/kubernetes/audit.log <br>
–authorization-mode=Node,RBAC <br>
–bind-address=0.0.0.0 <br>
–secure-port=6443 <br>
–client-ca-file=/etc/kubernetes/ssl/ca.pem <br>
–kubelet-client-certificate=/etc/kubernetes/ssl/kubernetes.pem <br>
–kubelet-client-key=/etc/kubernetes/ssl/kubernetes-key.pem <br>
–enable-swagger-ui=true <br>
–etcd-cafile=/etc/kubernetes/ssl/ca.pem <br>
–etcd-certfile=/etc/kubernetes/ssl/etcd.pem <br>
–etcd-keyfile=/etc/kubernetes/ssl/etcd-key.pem <br>
–etcd-servers=https://172.16.1.64:2379,<a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a>,<a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a> <br>
–event-ttl=1h <br>
–kubelet-https=true <br>
–insecure-bind-address=127.0.0.1 <br>
–insecure-port=8080 <br>
–service-account-key-file=/etc/kubernetes/ssl/ca-key.pem <br>
–service-cluster-ip-range=10.254.0.0/18 <br>
–service-node-port-range=30000-32000 <br>
–tls-cert-file=/etc/kubernetes/ssl/kubernetes.pem <br>
–tls-private-key-file=/etc/kubernetes/ssl/kubernetes-key.pem <br>
–enable-bootstrap-token-auth <br>
–v=1<br>
Restart=on-failure<br>
RestartSec=5<br>
Type=notify<br>
LimitNOFILE=65536</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="encryption-provider-config-替代之前-tokencsv-文件">–encryption-provider-config ，替代之前 token.csv 文件</span></h1>
<h1><span id="这里面要注意的是-service-node-port-range30000-32000">这里面要注意的是 --service-node-port-range=30000-32000</span></h1>
<h1><span id="这个地方是-映射外部端口时-的端口范围随机映射也在这个范围内映射指定映射端口必须也在这个范围内">这个地方是 映射外部端口时 的端口范围，随机映射也在这个范围内映射，指定映射端口必须也在这个范围内。</span></h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> </span><br><span class="line">### 启动 kube-apiserver</span><br></pre></td></tr></table></figure>
<p>systemctl daemon-reload<br>
systemctl enable kube-apiserver<br>
systemctl start kube-apiserver<br>
systemctl status kube-apiserver</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t kube-apiserver  和 journalctl -u kube-apiserver 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 配置 kube-controller-manager</span><br></pre></td></tr></table></figure>
<h1><span id="创建-kube-controller-managerservice-文件">创建 kube-controller-manager.service 文件</span></h1>
<p>vi /etc/systemd/system/kube-controller-manager.service</p>
<p>[Unit]<br>
Description=Kubernetes Controller Manager<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes</p>
<p>[Service]<br>
ExecStart=/usr/local/bin/kube-controller-manager <br>
–address=0.0.0.0 <br>
–master=http://127.0.0.1:8080 <br>
–allocate-node-cidrs=true <br>
–service-cluster-ip-range=10.254.0.0/18 <br>
–cluster-cidr=10.254.64.0/18 <br>
–cluster-signing-cert-file=/etc/kubernetes/ssl/ca.pem <br>
–cluster-signing-key-file=/etc/kubernetes/ssl/ca-key.pem <br>
–feature-gates=RotateKubeletServerCertificate=true <br>
–controllers=*,tokencleaner,bootstrapsigner <br>
–experimental-cluster-signing-duration=86700h0m0s <br>
–cluster-name=kubernetes <br>
–service-account-private-key-file=/etc/kubernetes/ssl/ca-key.pem <br>
–root-ca-file=/etc/kubernetes/ssl/ca.pem <br>
–leader-elect=true <br>
–node-monitor-grace-period=40s <br>
–node-monitor-period=5s <br>
–pod-eviction-timeout=5m0s <br>
–v=2<br>
Restart=on-failure<br>
RestartSec=5</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 启动 kube-controller-manager</span><br></pre></td></tr></table></figure>
<p>systemctl daemon-reload<br>
systemctl enable kube-controller-manager<br>
systemctl start kube-controller-manager<br>
systemctl status kube-controller-manager</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t kube-controller-manager  和 journalctl -u kube-controller-manager 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 配置 kube-scheduler</span><br></pre></td></tr></table></figure>
<h1><span id="创建-kube-schedulerservice-文件">创建 kube-scheduler.service 文件</span></h1>
<p>vi /etc/systemd/system/kube-scheduler.service</p>
<p>[Unit]<br>
Description=Kubernetes Scheduler<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes</p>
<p>[Service]<br>
ExecStart=/usr/local/bin/kube-scheduler <br>
–address=0.0.0.0 <br>
–master=http://127.0.0.1:8080 <br>
–leader-elect=true <br>
–v=1<br>
Restart=on-failure<br>
RestartSec=5</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">### 启动 kube-scheduler</span><br></pre></td></tr></table></figure>
<p>systemctl daemon-reload<br>
systemctl enable kube-scheduler<br>
systemctl start kube-scheduler<br>
systemctl status kube-scheduler</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line">### 验证 kube-scheduler 的 ha</span><br><span class="line"></span><br><span class="line">&gt; kube-scheduler 通过配置 leader-elect=true 自动选择 leader</span><br></pre></td></tr></table></figure>
<h1><span id="使用如下命令-可以查看-holderidentity-字段中的前缀-来判断-leader">使用如下命令 可以查看 holderIdentity 字段中的前缀 来判断 leader</span></h1>
<p>kubectl get endpoints kube-scheduler --namespace=kube-system  -o yaml</p>
<p>apiVersion: v1<br>
kind: Endpoints<br>
metadata:<br>
annotations:<br>
<a href="http://control-plane.alpha.kubernetes.io/leader:" target="_blank" rel="noopener">control-plane.alpha.kubernetes.io/leader:</a> '{“holderIdentity”:“kubernetes-2_84a37531-f846-11e8-a04c-000c29e78616”,“leaseDurationSeconds”:15,“acquireTime”:“2018-12-05T04:33:02Z”,“renewTime”:“2018-12-05T04:33:10Z”,“leaderTransitions”:4}'<br>
creationTimestamp: &quot;2018-10-09T02:38:12Z&quot;<br>
name: kube-scheduler<br>
namespace: kube-system<br>
resourceVersion: &quot;7718283&quot;<br>
selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler<br>
uid: 5dbb5a57-cb6c-11e8-8f42-000c2947006b</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"></span><br><span class="line">### 验证 Master 节点</span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 ~]# kubectl get componentstatuses<br>
NAME                 STATUS    MESSAGE              ERROR<br>
controller-manager   Healthy   ok<br>
scheduler            Healthy   ok<br>
etcd-2               Healthy   {“health”: “true”}<br>
etcd-0               Healthy   {“health”: “true”}<br>
etcd-1               Healthy   {“health”: “true”}</p>
<p>[root@kubernetes-65 ~]# kubectl get componentstatuses<br>
NAME                 STATUS    MESSAGE              ERROR<br>
controller-manager   Healthy   ok<br>
scheduler            Healthy   ok<br>
etcd-2               Healthy   {“health”: “true”}<br>
etcd-0               Healthy   {“health”: “true”}<br>
etcd-1               Healthy   {“health”: “true”}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> </span><br><span class="line"></span><br><span class="line">### 配置 kubelet 认证</span><br><span class="line"></span><br><span class="line">&gt; kubelet 授权 kube-apiserver 的一些操作 exec run logs 等</span><br></pre></td></tr></table></figure>
<h1><span id="rbac-只需创建一次就可以">RBAC 只需创建一次就可以</span></h1>
<p>kubectl create clusterrolebinding kube-apiserver:kubelet-apis --clusterrole=system:kubelet-api-admin --user kubernetes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 bootstrap kubeconfig 文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 注意: token 生效时间为 1day , 超过时间未创建自动失效，需要重新创建 token</span><br></pre></td></tr></table></figure>
<h1><span id="创建-集群所有-kubelet-的-token">创建 集群所有 kubelet 的 token</span></h1>
<p>[root@kubernetes-64 kubernetes]# kubeadm token create --description kubelet-bootstrap-token --groups system:bootstrappers:kubernetes-64 --kubeconfig ~/.kube/config</p>
<p>I1009 10:39:16.623409    3117 version.go:89] could not fetch a Kubernetes version from the internet: unable to get URL “<a href="https://dl.k8s.io/release/stable-1.txt" target="_blank" rel="noopener">https://dl.k8s.io/release/stable-1.txt</a>”: Get <a href="https://storage.googleapis.com/kubernetes-release/release/stable-1.txt:" target="_blank" rel="noopener">https://storage.googleapis.com/kubernetes-release/release/stable-1.txt:</a> dial tcp 172.217.25.16:443: connect: connection timed out<br>
I1009 10:39:16.623486    3117 version.go:94] falling back to the local client version: v1.13.1<br>
ado3mb.00vde0vkgvfbpz30</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 kubernetes]# kubeadm token create --description kubelet-bootstrap-token --groups system:bootstrappers:kubernetes-65 --kubeconfig ~/.kube/config</p>
<p>I1009 10:40:14.199418    3126 version.go:89] could not fetch a Kubernetes version from the internet: unable to get URL “<a href="https://dl.k8s.io/release/stable-1.txt" target="_blank" rel="noopener">https://dl.k8s.io/release/stable-1.txt</a>”: Get <a href="https://storage.googleapis.com/kubernetes-release/release/stable-1.txt:" target="_blank" rel="noopener">https://storage.googleapis.com/kubernetes-release/release/stable-1.txt:</a> dial tcp 172.217.25.16:443: connect: connection timed out<br>
I1009 10:40:14.199487    3126 version.go:94] falling back to the local client version: v1.13.1<br>
6xkesn.bmym9293ty2r1umr</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 kubernetes]# kubeadm token create --description kubelet-bootstrap-token --groups system:bootstrappers:kubernetes-66 --kubeconfig ~/.kube/config</p>
<p>I1009 10:40:42.919424    3136 version.go:89] could not fetch a Kubernetes version from the internet: unable to get URL “<a href="https://dl.k8s.io/release/stable-1.txt" target="_blank" rel="noopener">https://dl.k8s.io/release/stable-1.txt</a>”: Get <a href="https://storage.googleapis.com/kubernetes-release/release/stable-1.txt:" target="_blank" rel="noopener">https://storage.googleapis.com/kubernetes-release/release/stable-1.txt:</a> dial tcp 172.217.25.16:443: connect: connection timed out<br>
I1009 10:40:42.919501    3136 version.go:94] falling back to the local client version: v1.13.1<br>
6jj682.j7wgboa50f6agith</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="查看生成的-token">查看生成的 token</span></h1>
<p>[root@kubernetes-64 kubernetes]# kubeadm token list --kubeconfig ~/.kube/config<br>
TOKEN                     TTL       EXPIRES                     USAGES                   DESCRIPTION               EXTRA GROUPS<br>
6jj682.j7wgboa50f6agith   23h       2018-10-10T10:40:42+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:kubernetes-64<br>
6xkesn.bmym9293ty2r1umr   23h       2018-10-10T10:40:14+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:kubernetes-65<br>
ado3mb.00vde0vkgvfbpz30   23h       2018-10-10T10:39:16+08:00   authentication,signing   kubelet-bootstrap-token   system:bootstrappers:kubernetes-66</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 以下为了区分 会先生成 node 名称加 bootstrap.kubeconfig </span><br><span class="line">&gt;</span><br><span class="line">&gt;</span><br><span class="line">&gt;</span><br><span class="line">&gt; 生成 kubernetes-64</span><br></pre></td></tr></table></figure>
<h1><span id="生成-64-的-bootstrapkubeconfig">生成 64 的 bootstrap.kubeconfig</span></h1>
<h1><span id="配置集群参数">配置集群参数</span></h1>
<p>kubectl config set-cluster kubernetes <br>
–certificate-authority=/etc/kubernetes/ssl/ca.pem <br>
–embed-certs=true <br>
–server=https://127.0.0.1:6443 <br>
–kubeconfig=kubernetes-64-bootstrap.kubeconfig</p>
<h1><span id="配置客户端认证">配置客户端认证</span></h1>
<p>kubectl config set-credentials kubelet-bootstrap <br>
–token=6jj682.j7wgboa50f6agith <br>
–kubeconfig=kubernetes-64-bootstrap.kubeconfig</p>
<h1><span id="配置关联">配置关联</span></h1>
<p>kubectl config set-context default <br>
–cluster=kubernetes <br>
–user=kubelet-bootstrap <br>
–kubeconfig=kubernetes-64-bootstrap.kubeconfig</p>
<h1><span id="配置默认关联">配置默认关联</span></h1>
<p>kubectl config use-context default --kubeconfig=kubernetes-64-bootstrap.kubeconfig</p>
<h1><span id="拷贝生成的-kubernetes-64-bootstrapkubeconfig-文件">拷贝生成的 kubernetes-64-bootstrap.kubeconfig 文件</span></h1>
<p>mv kubernetes-64-bootstrap.kubeconfig /etc/kubernetes/bootstrap.kubeconfig</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; 生成 kubernetes-65</span><br></pre></td></tr></table></figure>
<h1><span id="生成-65-的-bootstrapkubeconfig">生成 65 的 bootstrap.kubeconfig</span></h1>
<h1><span id="配置集群参数">配置集群参数</span></h1>
<p>kubectl config set-cluster kubernetes <br>
–certificate-authority=/etc/kubernetes/ssl/ca.pem <br>
–embed-certs=true <br>
–server=https://127.0.0.1:6443 <br>
–kubeconfig=kubernetes-65-bootstrap.kubeconfig</p>
<h1><span id="配置客户端认证">配置客户端认证</span></h1>
<p>kubectl config set-credentials kubelet-bootstrap <br>
–token=1ua4d4.9bluufy3esw4lch6 <br>
–kubeconfig=kubernetes-65-bootstrap.kubeconfig</p>
<h1><span id="配置关联">配置关联</span></h1>
<p>kubectl config set-context default <br>
–cluster=kubernetes <br>
–user=kubelet-bootstrap <br>
–kubeconfig=kubernetes-65-bootstrap.kubeconfig</p>
<h1><span id="配置默认关联">配置默认关联</span></h1>
<p>kubectl config use-context default --kubeconfig=kubernetes-65-bootstrap.kubeconfig</p>
<h1><span id="拷贝生成的-kubernetes-65-bootstrapkubeconfig-文件">拷贝生成的 kubernetes-65-bootstrap.kubeconfig 文件</span></h1>
<p>scp kubernetes-65-bootstrap.kubeconfig 172.16.1.65:/etc/kubernetes/bootstrap.kubeconfig</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">&gt; 生成 kubernetes-66</span><br></pre></td></tr></table></figure>
<h1><span id="生成-66-的-bootstrapkubeconfig">生成 66 的 bootstrap.kubeconfig</span></h1>
<h1><span id="配置集群参数">配置集群参数</span></h1>
<p>kubectl config set-cluster kubernetes <br>
–certificate-authority=/etc/kubernetes/ssl/ca.pem <br>
–embed-certs=true <br>
–server=https://127.0.0.1:6443 <br>
–kubeconfig=kubernetes-66-bootstrap.kubeconfig</p>
<h1><span id="配置客户端认证">配置客户端认证</span></h1>
<p>kubectl config set-credentials kubelet-bootstrap <br>
–token=r8llj2.itme3y54ok531ops <br>
–kubeconfig=kubernetes-66-bootstrap.kubeconfig</p>
<h1><span id="配置关联">配置关联</span></h1>
<p>kubectl config set-context default <br>
–cluster=kubernetes <br>
–user=kubelet-bootstrap <br>
–kubeconfig=kubernetes-66-bootstrap.kubeconfig</p>
<h1><span id="配置默认关联">配置默认关联</span></h1>
<p>kubectl config use-context default --kubeconfig=kubernetes-66-bootstrap.kubeconfig</p>
<h1><span id="拷贝生成的-kubernetes-66-bootstrapkubeconfig-文件">拷贝生成的 kubernetes-66-bootstrap.kubeconfig 文件</span></h1>
<p>scp kubernetes-66-bootstrap.kubeconfig 172.16.1.66:/etc/kubernetes/bootstrap.kubeconfig</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置-bootstrap-rbac-权限">配置 bootstrap RBAC 权限</span></h1>
<p>kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --group=system:bootstrappers</p>
<h1><span id="否则报如下错误">否则报如下错误</span></h1>
<p>failed to run Kubelet: cannot create certificate signing request: <a href="http://certificatesigningrequests.certificates.k8s.io" target="_blank" rel="noopener">certificatesigningrequests.certificates.k8s.io</a> is forbidden: User “system:bootstrap:1jezb7” cannot create <a href="http://certificatesigningrequests.certificates.k8s.io" target="_blank" rel="noopener">certificatesigningrequests.certificates.k8s.io</a> at the cluster scope</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建自动批准相关 CSR 请求的 ClusterRole</span><br></pre></td></tr></table></figure>
<p>vi /etc/kubernetes/tls-instructs-csr.yaml</p>
<p>kind: ClusterRole<br>
apiVersion: <a href="http://rbac.authorization.k8s.io/v1" target="_blank" rel="noopener">rbac.authorization.k8s.io/v1</a><br>
metadata:<br>
name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver<br>
rules:</p>
<ul>
<li>apiGroups: [“<a href="http://certificates.k8s.io" target="_blank" rel="noopener">certificates.k8s.io</a>”]<br>
resources: [“certificatesigningrequests/selfnodeserver”]<br>
verbs: [“create”]</li>
</ul>
<h1><span id="导入-yaml-文件">导入 yaml 文件</span></h1>
<p>[root@kubernetes-64 opt]# kubectl apply -f /etc/kubernetes/tls-instructs-csr.yaml<br>
<a href="http://clusterrole.rbac.authorization.k8s.io" target="_blank" rel="noopener">clusterrole.rbac.authorization.k8s.io</a> “system:certificates.k8s.io:certificatesigningrequests:selfnodeserver” created</p>
<h1><span id="查看">查看</span></h1>
<p>[root@kubernetes-64 opt]# kubectl describe ClusterRole/system:certificates.k8s.io:certificatesigningrequests:selfnodeserver<br>
Name:         system:certificates.k8s.io:certificatesigningrequests:selfnodeserver<br>
Labels:       <none><br>
Annotations:  <a href="http://kubectl.kubernetes.io/last-applied-configuration=%7B%22apiVersion%22:%22rbac.authorization.k8s.io/v1%22,%22kind%22:%22ClusterRole%22,%22metadata%22:%7B%22annotations%22:%7B%7D,%22name%22:%22system:certificates.k8s.io:certificatesigningreq" target="_blank" rel="noopener">kubectl.kubernetes.io/last-applied-configuration={“apiVersion”:“rbac.authorization.k8s.io/v1”,“kind”:“ClusterRole”,“metadata”:{“annotations”:{},“name”:&quot;system:certificates.k8s.io:certificatesigningreq</a>…<br>
PolicyRule:<br>
Resources                                                      Non-Resource URLs  Resource Names  Verbs</none></p>
<hr>
<p><a href="http://certificatesigningrequests.certificates.k8s.io/selfnodeserver" target="_blank" rel="noopener">certificatesigningrequests.certificates.k8s.io/selfnodeserver</a>  []                 []              [create]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="将-clusterrole-绑定到适当的用户组">将 ClusterRole 绑定到适当的用户组</span></h1>
<h1><span id="自动批准-systembootstrappers-组用户-tls-bootstrapping-首次申请证书的-csr-请求">自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求</span></h1>
<p>kubectl create clusterrolebinding node-client-auto-approve-csr --clusterrole=system:certificates.k8s.io:certificatesigningrequests:nodeclient --group=system:bootstrappers</p>
<h1><span id="自动批准-systemnodes-组用户更新-kubelet-自身与-apiserver-通讯证书的-csr-请求">自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求</span></h1>
<p>kubectl create clusterrolebinding node-client-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeclient --group=system:nodes</p>
<h1><span id="自动批准-systemnodes-组用户更新-kubelet-10250-api-端口证书的-csr-请求">自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求</span></h1>
<p>kubectl create clusterrolebinding node-server-auto-renew-crt --clusterrole=system:certificates.k8s.io:certificatesigningrequests:selfnodeserver --group=system:nodes</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 kubelet.service 文件</span><br><span class="line"></span><br><span class="line">&gt; 关于 kubectl get node 中的 ROLES 的标签</span><br><span class="line"></span><br><span class="line">&gt; 单 Master 打标签 kubectl label node kubernetes-64 node-role.kubernetes.io/master=&quot;&quot;</span><br><span class="line">&gt;</span><br><span class="line">&gt; 这里需要将 单Master 更改为 NoSchedule</span><br><span class="line">&gt;</span><br><span class="line">&gt; 更新标签命令为 kubectl taint nodes kubernetes-64 node-role.kubernetes.io/master=:NoSchedule</span><br><span class="line">&gt;</span><br><span class="line">&gt; 既 Master 又是 node 打标签 kubectl label node kubernetes-65  node-role.kubernetes.io/master=&quot;&quot;</span><br><span class="line">&gt;</span><br><span class="line">&gt; 单 Node 打标签 kubectl label node kubernetes-66 node-role.kubernetes.io/node=&quot;&quot;</span><br><span class="line"></span><br><span class="line">&gt; 关于删除 label 可使用 - 号相连</span><br><span class="line">&gt; 如: kubectl label nodes kubernetes-65 node-role.kubernetes.io/node-</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 动态 kubelet 配置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 官方说明 https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/</span><br><span class="line">&gt; https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/</span><br><span class="line">&gt;</span><br><span class="line">&gt; https://github.com/kubernetes/kubernetes/blob/release-1.12/pkg/kubelet/apis/config/types.go</span><br></pre></td></tr></table></figure>
<h1><span id="创建-kubelet-目录">创建 kubelet 目录</span></h1>
<p>mkdir -p /var/lib/kubelet</p>
<p>vi /etc/systemd/system/kubelet.service</p>
<p>[Unit]<br>
Description=Kubernetes Kubelet<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes<br>
After=docker.service<br>
Requires=docker.service</p>
<p>[Service]<br>
WorkingDirectory=/var/lib/kubelet<br>
ExecStart=/usr/local/bin/kubelet <br>
–hostname-override=kubernetes-64 <br>
–pod-infra-container-image=jicki/pause-amd64:3.1 <br>
–bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig <br>
–kubeconfig=/etc/kubernetes/kubelet.kubeconfig <br>
–config=/etc/kubernetes/kubelet.config.json <br>
–cert-dir=/etc/kubernetes/ssl <br>
–logtostderr=true <br>
–v=2</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="创建-kubelet-config-配置文件">创建 kubelet config 配置文件</span></h1>
<p>vi /etc/kubernetes/kubelet.config.json</p>
<p>{<br>
“kind”: “KubeletConfiguration”,<br>
“apiVersion”: “<a href="http://kubelet.config.k8s.io/v1beta1" target="_blank" rel="noopener">kubelet.config.k8s.io/v1beta1</a>”,<br>
“authentication”: {<br>
“x509”: {<br>
“clientCAFile”: “/etc/kubernetes/ssl/ca.pem”<br>
},<br>
“webhook”: {<br>
“enabled”: true,<br>
“cacheTTL”: “2m0s”<br>
},<br>
“anonymous”: {<br>
“enabled”: false<br>
}<br>
},<br>
“authorization”: {<br>
“mode”: “Webhook”,<br>
“webhook”: {<br>
“cacheAuthorizedTTL”: “5m0s”,<br>
“cacheUnauthorizedTTL”: “30s”<br>
}<br>
},<br>
“address”: “172.16.1.64”,<br>
“port”: 10250,<br>
“readOnlyPort”: 0,<br>
“cgroupDriver”: “cgroupfs”,<br>
“hairpinMode”: “promiscuous-bridge”,<br>
“serializeImagePulls”: false,<br>
“RotateCertificates”: true,<br>
“featureGates”: {<br>
“RotateKubeletClientCertificate”: true,<br>
“RotateKubeletServerCertificate”: true<br>
},<br>
“MaxPods”: “512”,<br>
“failSwapOn”: false,<br>
“containerLogMaxSize”: “10Mi”,<br>
“containerLogMaxFiles”: 5,<br>
“clusterDomain”: “cluster.local.”,<br>
“clusterDNS”: [“10.254.0.2”]<br>
}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如上配置">如上配置:</span></h1>
<p>kubernetes-64    本机hostname<br>
10.254.0.2       预分配的 dns 地址<br>
cluster.local.   为 kubernetes 集群的 domain<br>
jicki/pause-amd64:3.1  这个是 pod 的基础镜像，既 gcr 的 <a href="http://gcr.io/google_containers/pause-amd64:3.1" target="_blank" rel="noopener">gcr.io/google_containers/pause-amd64:3.1</a> 镜像， 下载下来修改为自己的仓库中的比较快。<br>
“clusterDNS”: [“10.254.0.2”] 可配置多个 dns地址，逗号可开, 可配置宿主机dns.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 启动 kubelet</span><br></pre></td></tr></table></figure>
<p>systemctl daemon-reload<br>
systemctl enable kubelet<br>
systemctl start kubelet<br>
systemctl status kubelet</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t kubelet  和 journalctl -u kubelet 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 验证 nodes</span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 ~]# kubectl get nodes<br>
NAME            STATUS    ROLES     AGE       VERSION<br>
kubernetes-64   Ready     master    17h       v1.13.1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 查看 kubelet 生成文件</span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 ~]# ls -lt /etc/kubernetes/ssl/kubelet-*<br>
-rw------- 1 root root 1374 4月  23 11:55 /etc/kubernetes/ssl/kubelet-server-2018-04-23-11-55-38.pem<br>
lrwxrwxrwx 1 root root   58 4月  23 11:55 /etc/kubernetes/ssl/kubelet-server-current.pem -&gt; /etc/kubernetes/ssl/kubelet-server-2018-04-23-11-55-38.pem<br>
-rw-r–r-- 1 root root 1050 4月  23 11:55 /etc/kubernetes/ssl/kubelet-client.crt<br>
-rw------- 1 root root  227 4月  23 11:55 /etc/kubernetes/ssl/kubelet-client.key</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 配置 kube-proxy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 kube-proxy 证书</span><br></pre></td></tr></table></figure>
<h1><span id="证书方面由于我们node端没有装-cfssl">证书方面由于我们node端没有装 cfssl</span></h1>
<h1><span id="我们回到-master-端-机器-去配置证书然后拷贝过来">我们回到 master 端 机器 去配置证书，然后拷贝过来</span></h1>
<p>[root@kubernetes-64 ~]# cd /opt/ssl</p>
<p>vi kube-proxy-csr.json</p>
<p>{<br>
“CN”: “system:kube-proxy”,<br>
“hosts”: [],<br>
“key”: {<br>
“algo”: “rsa”,<br>
“size”: 2048<br>
},<br>
“names”: [<br>
{<br>
“C”: “CN”,<br>
“ST”: “ShenZhen”,<br>
“L”: “ShenZhen”,<br>
“O”: “k8s”,<br>
“OU”: “System”<br>
}<br>
]<br>
}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 生成 kube-proxy 证书和私钥</span><br></pre></td></tr></table></figure>
<p>/opt/local/cfssl/cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem <br>
-ca-key=/etc/kubernetes/ssl/ca-key.pem <br>
-config=/opt/ssl/config.json <br>
-profile=kubernetes  kube-proxy-csr.json | /opt/local/cfssl/cfssljson -bare kube-proxy</p>
<h1><span id="查看生成">查看生成</span></h1>
<p>ls kube-proxy*<br>
kube-proxy.csr  kube-proxy-csr.json  kube-proxy-key.pem  kube-proxy.pem</p>
<h1><span id="拷贝到目录">拷贝到目录</span></h1>
<p>cp kube-proxy* /etc/kubernetes/ssl/</p>
<p>scp kube-proxy* 172.16.1.65:/etc/kubernetes/ssl/</p>
<p>scp kube-proxy* 172.16.1.66:/etc/kubernetes/ssl/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 kube-proxy kubeconfig 文件</span><br></pre></td></tr></table></figure>
<h1><span id="配置集群">配置集群</span></h1>
<p>kubectl config set-cluster kubernetes <br>
–certificate-authority=/etc/kubernetes/ssl/ca.pem <br>
–embed-certs=true <br>
–server=https://127.0.0.1:6443 <br>
–kubeconfig=kube-proxy.kubeconfig</p>
<h1><span id="配置客户端认证">配置客户端认证</span></h1>
<p>kubectl config set-credentials kube-proxy <br>
–client-certificate=/etc/kubernetes/ssl/kube-proxy.pem <br>
–client-key=/etc/kubernetes/ssl/kube-proxy-key.pem <br>
–embed-certs=true <br>
–kubeconfig=kube-proxy.kubeconfig</p>
<h1><span id="配置关联">配置关联</span></h1>
<p>kubectl config set-context default <br>
–cluster=kubernetes <br>
–user=kube-proxy <br>
–kubeconfig=kube-proxy.kubeconfig</p>
<h1><span id="配置默认关联">配置默认关联</span></h1>
<p>kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</p>
<h1><span id="拷贝到需要的-node-端里">拷贝到需要的 node 端里</span></h1>
<p>scp kube-proxy.kubeconfig 172.16.1.65:/etc/kubernetes/</p>
<p>scp kube-proxy.kubeconfig 172.16.1.66:/etc/kubernetes/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建 kube-proxy.service 文件</span><br><span class="line"></span><br><span class="line">&gt;  1.10  官方 ipvs 已经是默认的配置</span><br><span class="line">&gt; --masquerade-all 必须添加这项配置，否则 创建 svc 在 ipvs 不会添加规则</span><br><span class="line"></span><br><span class="line">&gt; 打开 ipvs 需要安装 ipvsadm  ipset conntrack 软件， 在 node 中安装 </span><br><span class="line">&gt; yum install ipset ipvsadm conntrack-tools.x86_64 -y</span><br><span class="line"></span><br><span class="line">&gt;</span><br><span class="line">&gt; yaml 配置文件中的 参数如下: </span><br><span class="line">&gt;</span><br><span class="line">&gt; https://github.com/kubernetes/kubernetes/blob/master/pkg/proxy/apis/config/types.go</span><br></pre></td></tr></table></figure>
<p>cd /etc/kubernetes/</p>
<p>vi  kube-proxy.config.yaml</p>
<p>apiVersion: <a href="http://kubeproxy.config.k8s.io/v1alpha1" target="_blank" rel="noopener">kubeproxy.config.k8s.io/v1alpha1</a><br>
bindAddress: 172.16.1.66<br>
clientConnection:<br>
kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig<br>
clusterCIDR: 10.254.64.0/18<br>
healthzBindAddress: 172.16.1.66:10256<br>
hostnameOverride: kubernetes-66<br>
kind: KubeProxyConfiguration<br>
metricsBindAddress: 172.16.1.66:10249<br>
mode: “ipvs”</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="创建-kube-proxy-目录">创建 kube-proxy 目录</span></h1>
<p>mkdir -p /var/lib/kube-proxy</p>
<p>vi /etc/systemd/system/kube-proxy.service</p>
<p>[Unit]<br>
Description=Kubernetes Kube-Proxy Server<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes<br>
After=network.target</p>
<p>[Service]<br>
WorkingDirectory=/var/lib/kube-proxy<br>
ExecStart=/usr/local/bin/kube-proxy <br>
–config=/etc/kubernetes/kube-proxy.config.yaml <br>
–logtostderr=true <br>
–v=1<br>
Restart=on-failure<br>
RestartSec=5<br>
LimitNOFILE=65536</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 启动 kube-proxy</span><br></pre></td></tr></table></figure>
<p>systemctl daemon-reload<br>
systemctl enable kube-proxy<br>
systemctl start kube-proxy<br>
systemctl status kube-proxy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t kube-proxy  和 journalctl -u kube-proxy 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="检查-ipvs">检查  ipvs</span></h1>
<p>[root@kubernetes-65 ~]# ipvsadm -L -n<br>
IP Virtual Server version 1.2.1 (size=4096)<br>
Prot LocalAddress:Port Scheduler Flags<br>
-&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn<br>
TCP  10.254.0.1:443 rr persistent 10800<br>
-&gt; 172.16.1.64:6443             Masq    1      0          0<br>
-&gt; 172.16.1.65:6443             Masq    1      0          0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t kube-proxy  和 journalctl -u kube-proxy 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">#### 至此 Master 端 与 Master and Node 端的安装完毕</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">##  Node 端 </span><br><span class="line"></span><br><span class="line">&gt; 单 Node 部分 需要部署的组件有 docker  calico  kubelet  kube-proxy 这几个组件。</span><br><span class="line">Node 节点 基于 Nginx 负载 API 做 Master HA</span><br></pre></td></tr></table></figure>
<h1><span id="master-之间除-api-server-以外其他组件通过-etcd-选举api-server-默认不作处理">master 之间除 api server 以外其他组件通过 etcd 选举，api server 默认不作处理；</span></h1>
<p>在每个 node 上启动一个 nginx，每个 nginx 反向代理所有 api server;<br>
node 上 kubelet、kube-proxy 连接本地的 nginx 代理端口;<br>
当 nginx 发现无法连接后端时会自动踢掉出问题的 api server，从而实现 api server 的 HA;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">![ HAMaster][2]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 发布证书</span><br></pre></td></tr></table></figure>
<h1><span id="all-node">ALL node</span></h1>
<p>mkdir -p /etc/kubernetes/ssl/</p>
<p>scp ca.pem kube-proxy.pem kube-proxy-key.pem  node-*:/etc/kubernetes/ssl/</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 创建Nginx 代理</span><br><span class="line"></span><br><span class="line">&gt; 在每个 node 都必须创建一个 Nginx 代理， 这里特别注意， 当 Master 也做为 Node 的时候 不需要配置 Nginx-proxy</span><br></pre></td></tr></table></figure>
<h1><span id="创建配置目录">创建配置目录</span></h1>
<p>mkdir -p /etc/nginx</p>
<h1><span id="写入代理配置">写入代理配置</span></h1>
<p>cat &lt;&lt; EOF &gt;&gt; /etc/nginx/nginx.conf<br>
error_log stderr notice;</p>
<p>worker_processes auto;<br>
events {<br>
multi_accept on;<br>
use epoll;<br>
worker_connections 1024;<br>
}</p>
<p>stream {<br>
upstream kube_apiserver {<br>
least_conn;<br>
server 172.16.1.64:6443;<br>
server 172.16.1.65:6443;<br>
}</p>
<pre><code>server {
    listen        0.0.0.0:6443;
    proxy_pass    kube_apiserver;
    proxy_timeout 10m;
    proxy_connect_timeout 1s;
}
</code></pre>
<p>}<br>
EOF</p>
<h1><span id="更新权限">更新权限</span></h1>
<p>chmod +r /etc/nginx/nginx.conf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置-nginx-基于-docker-进程然后配置-systemd-来启动">配置 Nginx 基于 docker 进程，然后配置 systemd 来启动</span></h1>
<p>cat &lt;&lt; EOF &gt;&gt; /etc/systemd/system/nginx-proxy.service<br>
[Unit]<br>
Description=kubernetes apiserver docker wrapper<br>
Wants=docker.socket<br>
After=docker.service</p>
<p>[Service]<br>
User=root<br>
PermissionsStartOnly=true<br>
ExecStart=/usr/bin/docker run -p 127.0.0.1:6443:6443 \<br>
-v /etc/nginx:/etc/nginx \<br>
–name nginx-proxy \<br>
–net=host \<br>
–restart=on-failure:5 \<br>
–memory=512M \<br>
nginx:1.13.7-alpine<br>
ExecStartPre=-/usr/bin/docker rm -f nginx-proxy<br>
ExecStop=/usr/bin/docker stop nginx-proxy<br>
Restart=always<br>
RestartSec=15s<br>
TimeoutStartSec=30s</p>
<p>[Install]<br>
WantedBy=multi-user.target<br>
EOF</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="启动-nginx">启动 Nginx</span></h1>
<p>systemctl daemon-reload<br>
systemctl start nginx-proxy<br>
systemctl enable nginx-proxy<br>
systemctl status nginx-proxy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 配置 Kubelet.service 文件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### systemd kubelet 配置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#### 动态 kubelet 配置</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 官方说明 https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/</span><br><span class="line">&gt; https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/</span><br><span class="line">&gt;</span><br><span class="line">&gt; https://github.com/kubernetes/kubernetes/blob/release-1.12/pkg/kubelet/apis/config/types.go</span><br></pre></td></tr></table></figure>
<h1><span id="创建-kubelet-目录">创建 kubelet 目录</span></h1>
<p>vi /etc/systemd/system/kubelet.service</p>
<p>[Unit]<br>
Description=Kubernetes Kubelet<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes<br>
After=docker.service<br>
Requires=docker.service</p>
<p>[Service]<br>
WorkingDirectory=/var/lib/kubelet<br>
ExecStart=/usr/local/bin/kubelet <br>
–hostname-override=kubernetes-64 <br>
–pod-infra-container-image=jicki/pause-amd64:3.1 <br>
–bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig <br>
–kubeconfig=/etc/kubernetes/kubelet.kubeconfig <br>
–config=/etc/kubernetes/kubelet.config.json <br>
–cert-dir=/etc/kubernetes/ssl <br>
–logtostderr=true <br>
–v=2</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="创建-kubelet-config-配置文件">创建 kubelet config 配置文件</span></h1>
<p>vi /etc/kubernetes/kubelet.config.json</p>
<p>{<br>
“kind”: “KubeletConfiguration”,<br>
“apiVersion”: “<a href="http://kubelet.config.k8s.io/v1beta1" target="_blank" rel="noopener">kubelet.config.k8s.io/v1beta1</a>”,<br>
“authentication”: {<br>
“x509”: {<br>
“clientCAFile”: “/etc/kubernetes/ssl/ca.pem”<br>
},<br>
“webhook”: {<br>
“enabled”: true,<br>
“cacheTTL”: “2m0s”<br>
},<br>
“anonymous”: {<br>
“enabled”: false<br>
}<br>
},<br>
“authorization”: {<br>
“mode”: “Webhook”,<br>
“webhook”: {<br>
“cacheAuthorizedTTL”: “5m0s”,<br>
“cacheUnauthorizedTTL”: “30s”<br>
}<br>
},<br>
“address”: “172.16.1.66”,<br>
“port”: 10250,<br>
“readOnlyPort”: 0,<br>
“cgroupDriver”: “cgroupfs”,<br>
“hairpinMode”: “promiscuous-bridge”,<br>
“serializeImagePulls”: false,<br>
“featureGates”: {<br>
“RotateKubeletClientCertificate”: true,<br>
“RotateKubeletServerCertificate”: true<br>
},<br>
“MaxPods”: “512”,<br>
“failSwapOn”: false,<br>
“containerLogMaxSize”: “10Mi”,<br>
“containerLogMaxFiles”: 5,<br>
“clusterDomain”: “cluster.local.”,<br>
“clusterDNS”: [“10.254.0.2”]<br>
}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="启动-kubelet">启动 kubelet</span></h1>
<p>systemctl daemon-reload<br>
systemctl enable kubelet<br>
systemctl start kubelet<br>
systemctl status kubelet</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 配置 kube-proxy.service</span><br></pre></td></tr></table></figure>
<p>cd /etc/kubernetes/</p>
<p>vi  kube-proxy.config.yaml</p>
<p>apiVersion: <a href="http://kubeproxy.config.k8s.io/v1alpha1" target="_blank" rel="noopener">kubeproxy.config.k8s.io/v1alpha1</a><br>
bindAddress: 172.16.1.66<br>
clientConnection:<br>
kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig<br>
clusterCIDR: 10.254.64.0/18<br>
healthzBindAddress: 172.16.1.66:10256<br>
hostnameOverride: kubernetes-66<br>
kind: KubeProxyConfiguration<br>
metricsBindAddress: 172.16.1.66:10249<br>
mode: “ipvs”</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="创建-kube-proxy-目录">创建 kube-proxy 目录</span></h1>
<p>vi /etc/systemd/system/kube-proxy.service</p>
<p>[Unit]<br>
Description=Kubernetes Kube-Proxy Server<br>
Documentation=https://github.com/GoogleCloudPlatform/kubernetes<br>
After=network.target</p>
<p>[Service]<br>
WorkingDirectory=/var/lib/kube-proxy<br>
ExecStart=/usr/local/bin/kube-proxy <br>
–config=/etc/kubernetes/kube-proxy.config.yaml <br>
–logtostderr=true <br>
–v=1<br>
Restart=on-failure<br>
RestartSec=5<br>
LimitNOFILE=65536</p>
<p>[Install]<br>
WantedBy=multi-user.target</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="启动">启动</span></h1>
<p>systemctl daemon-reload<br>
systemctl enable kube-proxy<br>
systemctl start kube-proxy<br>
systemctl status kube-proxy</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置 Flannel 网络</span><br><span class="line"></span><br><span class="line">&gt; 公有云如 阿里云 华为云 可能无法使用 flannel 的 host-gw 模式，请使用 vxlan 或 calico 网络</span><br><span class="line">&gt;</span><br><span class="line">&gt; flannel 网络只部署在 kube-proxy 相关机器</span><br><span class="line">&gt;</span><br><span class="line">&gt; 个人 百度盘 下载 https://pan.baidu.com/s/1_A3zzurG5vV40-FnyA8uWg</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
<p>rpm -ivh flannel-0.10.0-1.x86_64.rpm</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置-flannel">配置 flannel</span></h1>
<h1><span id="由于我们docker更改了-dockerserviced-的路径">由于我们docker更改了 docker.service.d 的路径</span></h1>
<h1><span id="所以这里把-flannelconf-的配置拷贝到-这个目录去">所以这里把 flannel.conf 的配置拷贝到 这个目录去</span></h1>
<p>mv /usr/lib/systemd/system/docker.service.d/flannel.conf /etc/systemd/system/docker.service.d</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置-flannel-网段">配置 flannel 网段</span></h1>
<p>etcdctl --endpoints=https://172.16.1.64:2379,<a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a>,<a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a><br>
–cert-file=/etc/kubernetes/ssl/etcd.pem <br>
–ca-file=/etc/kubernetes/ssl/ca.pem <br>
–key-file=/etc/kubernetes/ssl/etcd-key.pem <br>
set /flannel/network/config \ ‘{“Network”:“10.254.64.0/18”,“SubnetLen”:24,“Backend”:{“Type”:“host-gw”}}’</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="修改-flanneld-配置">修改 flanneld 配置</span></h1>
<p>vi /etc/sysconfig/flanneld</p>
<h1><span id="flanneld-configuration-options">Flanneld configuration options</span></h1>
<h1><span id="etcd-地址">etcd 地址</span></h1>
<p>FLANNEL_ETCD_ENDPOINTS=“<a href="https://172.16.1.64:2379" target="_blank" rel="noopener">https://172.16.1.64:2379</a>,<a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a>,<a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a>”</p>
<h1><span id="配置为上面的路径-flannelnetwork">配置为上面的路径 flannel/network</span></h1>
<p>FLANNEL_ETCD_PREFIX=&quot;/flannel/network&quot;</p>
<h1><span id="其他的配置可查看-flanneld-help这里添加了-etcd-ssl-认证">其他的配置，可查看 flanneld --help,这里添加了 etcd ssl 认证</span></h1>
<p>FLANNEL_OPTIONS=&quot;-ip-masq=true -etcd-cafile=/etc/kubernetes/ssl/ca.pem -etcd-certfile=/etc/kubernetes/ssl/etcd.pem -etcd-keyfile=/etc/kubernetes/ssl/etcd-key.pem -iface=em1&quot;</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="启动-flannel">启动 flannel</span></h1>
<p>systemctl daemon-reload<br>
systemctl enable flanneld<br>
systemctl start flanneld<br>
systemctl status flanneld</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="如果报错-请使用">如果报错 请使用</span></h1>
<p>journalctl -f -t flanneld  和 journalctl -u flanneld 来定位问题</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置完毕重启-docker">配置完毕，重启 docker</span></h1>
<p>systemctl daemon-reload<br>
systemctl enable docker<br>
systemctl restart docker<br>
systemctl status docker</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="重启-kubelet">重启 kubelet</span></h1>
<p>systemctl daemon-reload<br>
systemctl restart kubelet<br>
systemctl status kubelet</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="验证-网络">验证 网络</span></h1>
<p>ifconfig  查看  docker0 网络 是否已经更改为配置IP网段</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置 Calico 网络</span><br><span class="line"></span><br><span class="line">&gt; 官方文档 https://docs.projectcalico.org/v3.4/introduction</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 下载 Calico yaml</span><br></pre></td></tr></table></figure>
<h1><span id="下载-yaml-文件">下载 yaml 文件</span></h1>
<p>wget <a href="https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/calico.yaml" target="_blank" rel="noopener">https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/calico.yaml</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">## 下载镜像</span><br></pre></td></tr></table></figure>
<h1><span id="下载-镜像">下载 镜像</span></h1>
<h1><span id="国外镜像-有墙">国外镜像 有墙</span></h1>
<p><a href="http://quay.io/calico/node:v3.3.1" target="_blank" rel="noopener">quay.io/calico/node:v3.3.1</a><br>
<a href="http://quay.io/calico/cni:v3.3.1" target="_blank" rel="noopener">quay.io/calico/cni:v3.3.1</a><br>
<a href="http://quay.io/calico/kube-controllers:v3.3.1" target="_blank" rel="noopener">quay.io/calico/kube-controllers:v3.3.1</a></p>
<h1><span id="国内镜像">国内镜像</span></h1>
<p>jicki/node:v3.3.1<br>
jicki/cni:v3.3.1<br>
jicki/kube-controllers:v3.3.1</p>
<h1><span id="替换镜像">替换镜像</span></h1>
<p>sed -i ‘s/quay.io/calico/jicki/g’  calico.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 修改配置</span><br></pre></td></tr></table></figure>
<p>vi calico.yaml</p>
<h1><span id="注意修改如下选项">注意修改如下选项:</span></h1>
<h1><span id="etcd-地址">etcd 地址</span></h1>
<p>etcd_endpoints: “<a href="https://172.16.1.64:2379" target="_blank" rel="noopener">https://172.16.1.64:2379</a>,<a href="https://172.16.1.65:2379" target="_blank" rel="noopener">https://172.16.1.65:2379</a>,<a href="https://172.16.1.66:2379" target="_blank" rel="noopener">https://172.16.1.66:2379</a>”</p>
<h1><span id="etcd-证书路径">etcd 证书路径</span></h1>
<h1><span id="if-youre-using-tls-enabled-etcd-uncomment-the-following">If you’re using TLS enabled etcd uncomment the following.</span></h1>
<h1><span id="you-must-also-populate-the-secret-below-with-these-files">You must also populate the Secret below with these files.</span></h1>
<pre><code>etcd_ca: &quot;/calico-secrets/etcd-ca&quot;  
etcd_cert: &quot;/calico-secrets/etcd-cert&quot;
etcd_key: &quot;/calico-secrets/etcd-key&quot;  
</code></pre>
<h1><span id="etcd-证书-base64-地址-执行里面的命令生成的证书-base64-码填入里面">etcd 证书 base64 地址 (执行里面的命令生成的证书 base64 码，填入里面)</span></h1>
<p>data:<br>
etcd-key: (cat /etc/kubernetes/ssl/etcd-key.pem | base64 | tr -d ‘\n’)<br>
etcd-cert: (cat /etc/kubernetes/ssl/etcd.pem | base64 | tr -d ‘\n’)<br>
etcd-ca: (cat /etc/kubernetes/ssl/ca.pem | base64 | tr -d ‘\n’)</p>
<h1><span id="修改-pods-分配的-ip-段">修改 pods 分配的 IP 段</span></h1>
<pre><code>        - name: CALICO_IPV4POOL_CIDR
          value: &quot;10.254.64.0/18&quot;
</code></pre>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="导入-yaml-文件">导入 yaml 文件</span></h1>
<p>[root@kubernetes-64 ~]# kubectl apply -f calico.yaml<br>
configmap/calico-config created<br>
secret/calico-etcd-secrets created<br>
daemonset.extensions/calico-node created<br>
serviceaccount/calico-node created<br>
deployment.extensions/calico-kube-controllers created<br>
serviceaccount/calico-kube-controllers created<br>
<a href="http://clusterrole.rbac.authorization.k8s.io/calico-kube-controllers" target="_blank" rel="noopener">clusterrole.rbac.authorization.k8s.io/calico-kube-controllers</a> created<br>
<a href="http://clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers" target="_blank" rel="noopener">clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers</a> created<br>
<a href="http://clusterrole.rbac.authorization.k8s.io/calico-node" target="_blank" rel="noopener">clusterrole.rbac.authorization.k8s.io/calico-node</a> created<br>
<a href="http://clusterrolebinding.rbac.authorization.k8s.io/calico-node" target="_blank" rel="noopener">clusterrolebinding.rbac.authorization.k8s.io/calico-node</a> created</p>
<h1><span id="查看服务">查看服务</span></h1>
<p>[root@kubernetes-64 ~]# kubectl get pods -n kube-system<br>
NAME                                       READY   STATUS    RESTARTS   AGE<br>
calico-kube-controllers-5d94b577bb-rzl7d   1/1     Running   0          52s<br>
calico-node-4cbrl                          1/1     Running   0          52s<br>
calico-node-9t7kj                          1/1     Running   0          52s<br>
calico-node-hc4x6                          1/1     Running   0          52s</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 修改 kubelet 配置</span><br></pre></td></tr></table></figure>
<h1><span id="kubelet-需要增加-cni-插件-network-plugincni">kubelet 需要增加 cni 插件    --network-plugin=cni</span></h1>
<p>vi /etc/systemd/system/kubelet.service</p>
<p>–network-plugin=cni \</p>
<h1><span id="重新加载配置">重新加载配置</span></h1>
<p>systemctl daemon-reload<br>
systemctl restart kubelet.service<br>
systemctl status kubelet.service</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">## 检查网络</span><br></pre></td></tr></table></figure>
<h1><span id="查看-node-中网络状况">查看 node 中网络状况</span></h1>
<p>[root@kubernetes-64 ~]# ifconfig</p>
<p>tunl0: flags=193&lt;UP,RUNNING,NOARP&gt;  mtu 1440<br>
inet 10.254.95.64  netmask 255.255.255.255<br>
tunnel   txqueuelen 1  (IPIP Tunnel)<br>
RX packets 2  bytes 168 (168.0 B)<br>
RX errors 0  dropped 0  overruns 0  frame 0<br>
TX packets 2  bytes 168 (168.0 B)<br>
TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</p>
<p>[root@kubernetes-65 ~]# ifconfig</p>
<p>tunl0: flags=193&lt;UP,RUNNING,NOARP&gt;  mtu 1440<br>
inet 10.254.116.128  netmask 255.255.255.255<br>
tunnel   txqueuelen 1  (IPIP Tunnel)<br>
RX packets 0  bytes 0 (0.0 B)<br>
RX errors 0  dropped 0  overruns 0  frame 0<br>
TX packets 0  bytes 0 (0.0 B)<br>
TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</p>
<p>[root@kubernetes-66 ~]# ifconfig</p>
<p>tunl0: flags=193&lt;UP,RUNNING,NOARP&gt;  mtu 1440<br>
inet 10.254.70.64  netmask 255.255.255.255<br>
tunnel   txqueuelen 1  (IPIP Tunnel)<br>
RX packets 0  bytes 0 (0.0 B)<br>
RX errors 0  dropped 0  overruns 0  frame 0<br>
TX packets 0  bytes 0 (0.0 B)<br>
TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">## 安装 calicoctl</span><br><span class="line"></span><br><span class="line">&gt; calicoctl 是 calico 网络的管理客户端, 只需要在一台 node 里配置既可。</span><br></pre></td></tr></table></figure>
<h1><span id="下载-二进制文件">下载 二进制文件</span></h1>
<p>curl -O -L <a href="https://github.com/projectcalico/calicoctl/releases/download/v3.2.3/calicoctl" target="_blank" rel="noopener">https://github.com/projectcalico/calicoctl/releases/download/v3.2.3/calicoctl</a></p>
<p>mv calicoctl /usr/local/bin/</p>
<p>chmod +x /usr/local/bin/calicoctl</p>
<h1><span id="创建-calicoctlcfg-配置文件">创建 calicoctl.cfg 配置文件</span></h1>
<p>mkdir /etc/calico</p>
<p>vi /etc/calico/calicoctl.cfg</p>
<p>apiVersion: <a href="http://projectcalico.org/v3" target="_blank" rel="noopener">projectcalico.org/v3</a><br>
kind: CalicoAPIConfig<br>
metadata:<br>
spec:<br>
datastoreType: &quot;kubernetes&quot;<br>
kubeconfig: “/root/.kube/config”</p>
<h1><span id="查看-calico-状态">查看 calico 状态</span></h1>
<p>[root@kubernetes-64 ~]# calicoctl node status<br>
Calico process is running.</p>
<p>IPv4 BGP status<br>
±---------------±------------------±------±---------±------------+<br>
|  PEER ADDRESS  |     PEER TYPE     | STATE |  SINCE   |    INFO     |<br>
±---------------±------------------±------±---------±------------+<br>
|  172.16.1.65   | node-to-node mesh | up    | 01:10:35 | Established |<br>
|  172.16.1.66   | node-to-node mesh | up    | 01:10:35 | Established |<br>
±---------------±------------------±------±---------±------------+</p>
<p>IPv6 BGP status<br>
No IPv6 peers found.</p>
<p>[root@kubernetes-64 ~]# calicoctl get node<br>
NAME<br>
kubernetes-64<br>
kubernetes-65<br>
kubernetes-66</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 测试集群</span><br></pre></td></tr></table></figure>
<h1><span id="创建一个-nginx-deplyment">创建一个 nginx deplyment</span></h1>
<p>apiVersion: apps/v1<br>
kind: Deployment<br>
metadata:<br>
name: nginx-dm<br>
spec:<br>
replicas: 3<br>
selector:<br>
matchLabels:<br>
name: nginx<br>
template:<br>
metadata:<br>
labels:<br>
name: nginx<br>
spec:<br>
containers:<br>
- name: nginx<br>
image: nginx:alpine<br>
imagePullPolicy: IfNotPresent<br>
ports:<br>
- containerPort: 80<br>
name: http</p>
<hr>
<p>apiVersion: v1<br>
kind: Service<br>
metadata:<br>
name: nginx-svc<br>
spec:<br>
ports:<br>
- port: 80<br>
name: http<br>
targetPort: 80<br>
protocol: TCP<br>
selector:<br>
name: nginx</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 ~]# kubectl get pods -o wide<br>
NAME                        READY     STATUS    RESTARTS   AGE       IP            NODE<br>
nginx-dm-84f8f49555-dzpm9   1/1       Running   0          6s        10.254.90.2   kubernetes-65<br>
nginx-dm-84f8f49555-qbnvv   1/1       Running   0          6s        10.254.66.2   k8s-master-66</p>
<p>[root@kubernetes-64 ~]# kubectl get svc -o wide<br>
NAME         TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE       SELECTOR<br>
kubernetes   ClusterIP   10.254.0.1      <none>        443/TCP   2h        <none><br>
nginx-svc    ClusterIP   10.254.41.39   <none>        80/TCP    1m</none></none></none></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="在-安装了-网络的节点-里-curl">在 安装了  网络的节点 里 curl</span></h1>
<p>[root@kubernetes-64 ~]# curl 10.254.51.137</p>
<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1><span id="welcome-to-nginx">Welcome to nginx!</span></h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/" target="_blank" rel="noopener">nginx.org</a>.<br>
Commercial support is available at
<a href="http://nginx.com/" target="_blank" rel="noopener">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="查看-ipvs-规则">查看 ipvs 规则</span></h1>
<p>[root@kubernetes-65 ~]# ipvsadm -L -n<br>
IP Virtual Server version 1.2.1 (size=4096)<br>
Prot LocalAddress:Port Scheduler Flags<br>
-&gt; RemoteAddress:Port           Forward Weight ActiveConn InActConn<br>
TCP  10.254.0.1:443 rr persistent 10800<br>
-&gt; 172.16.1.64:6443             Masq    1      0          0<br>
-&gt; 172.16.1.65:6443             Masq    1      0          0<br>
TCP  10.254.41.39:80 rr<br>
-&gt; 10.254.66.2:80               Masq    1      0          0<br>
-&gt; 10.254.90.2:80               Masq    1      0          1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 配置 CoreDNS</span><br><span class="line"></span><br><span class="line">&gt; 官方 地址  https://coredns.io</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 下载 yaml 文件</span><br></pre></td></tr></table></figure>
<p>wget <a href="https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed" target="_blank" rel="noopener">https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed</a></p>
<p>mv coredns.yaml.sed coredns.yaml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 1.2.x 版本中 Corefile 部分更新了点东西，使用如下替换整个 Corefile 部分</span><br></pre></td></tr></table></figure>
<h1><span id="vi-corednsyaml">vi coredns.yaml</span></h1>
<p>…<br>
data:<br>
Corefile: |<br>
.:53 {<br>
errors<br>
health<br>
kubernetes cluster.local 10.254.0.0/18 {<br>
pods insecure<br>
upstream<br>
fallthrough in-addr.arpa ip6.arpa<br>
}<br>
prometheus :9153<br>
proxy . /etc/resolv.conf<br>
cache 30<br>
loop<br>
reload<br>
loadbalance<br>
}<br>
…<br>
clusterIP: 10.254.0.2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置说明">配置说明</span></h1>
<h1><span id="这里-kubernetes-clusterlocal-为-创建-svc-的-ip-段">这里 kubernetes cluster.local 为 创建 svc 的 IP 段</span></h1>
<p>kubernetes cluster.local 10.254.0.0/18</p>
<h1><span id="clusterip-为-指定-dns-的-ip">clusterIP  为 指定 DNS 的 IP</span></h1>
<p>clusterIP: 10.254.0.2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 导入 yaml 文件</span><br></pre></td></tr></table></figure>
<h1><span id="导入">导入</span></h1>
<p>[root@kubernetes-64 coredns]# kubectl apply -f coredns.yaml<br>
serviceaccount/coredns created<br>
<a href="http://clusterrole.rbac.authorization.k8s.io/system:coredns" target="_blank" rel="noopener">clusterrole.rbac.authorization.k8s.io/system:coredns</a> created<br>
<a href="http://clusterrolebinding.rbac.authorization.k8s.io/system:coredns" target="_blank" rel="noopener">clusterrolebinding.rbac.authorization.k8s.io/system:coredns</a> created<br>
configmap/coredns created<br>
deployment.extensions/coredns created<br>
service/kube-dns created</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 查看 coredns 服务</span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 coredns]# kubectl get pod,svc -n kube-system<br>
NAME                           READY     STATUS    RESTARTS   AGE<br>
pod/coredns-6975654877-nzhgr   1/1       Running   0          23s<br>
pod/coredns-6975654877-qn4bp   1/1       Running   0          23s</p>
<p>NAME               TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE<br>
service/kube-dns   ClusterIP   10.254.0.2   <none>        53/UDP,53/TCP   23s</none></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## 检查日志</span><br></pre></td></tr></table></figure>
<p>[root@kubernetes-64 coredns]# kubectl logs -n kube-system pod/coredns-6975654877-nzhgr<br>
.:53<br>
2018/08/09 02:11:11 [INFO] CoreDNS-1.2.0<br>
2018/08/09 02:11:11 [INFO] linux/amd64, go1.10.3, 2e322f6<br>
CoreDNS-1.2.0<br>
linux/amd64, go1.10.3, 2e322f6<br>
2018/08/09 02:11:11 [INFO] plugin/reload: Running configuration MD5 = 271feea1e1cf54e66a65c7ffcf2b89ad</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 验证 dns 服务</span><br><span class="line"></span><br><span class="line">&gt; 在验证 dns 之前，在 dns 未部署之前创建的 pod 与 deployment 等，都必须删除，重新部署，否则无法解析</span><br></pre></td></tr></table></figure>
<h1><span id="创建一个-pods-来测试一下-dns">创建一个 pods 来测试一下 dns</span></h1>
<p>apiVersion: v1<br>
kind: Pod<br>
metadata:<br>
name: alpine<br>
spec:<br>
containers:</p>
<ul>
<li>name: alpine<br>
image: alpine<br>
command:
<ul>
<li>sleep</li>
<li>“3600”</li>
</ul>
</li>
</ul>
<h1><span id="查看-创建的服务">查看 创建的服务</span></h1>
<p>[root@kubernetes-64 yaml]# kubectl get pods,svc<br>
NAME                           READY     STATUS    RESTARTS   AGE<br>
po/alpine                      1/1       Running   0          19s<br>
po/nginx-dm-84f8f49555-tmqzm   1/1       Running   0          23s<br>
po/nginx-dm-84f8f49555-wdk67   1/1       Running   0          23s</p>
<p>NAME             TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE<br>
svc/kubernetes   ClusterIP   10.254.0.1      <none>        443/TCP   5h<br>
svc/nginx-svc    ClusterIP   10.254.40.179   <none>        80/TCP    23s</none></none></p>
<h1><span id="测试">测试</span></h1>
<p>[root@kubernetes-64 ~]# kubectl exec -it alpine nslookup nginx-svc<br>
nslookup: can’t resolve ‘(null)’: Name does not resolve</p>
<p>Name:      nginx-svc<br>
Address 1: 10.254.40.179 nginx-svc.default.svc.cluster.local</p>
<p>[root@kubernetes-64 yaml]# kubectl exec -it alpine nslookup kubernetes<br>
nslookup: can’t resolve ‘(null)’: Name does not resolve</p>
<p>Name:      kubernetes<br>
Address 1: 10.254.0.1 kubernetes.default.svc.cluster.local</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 部署 DNS 自动伸缩</span><br><span class="line"></span><br><span class="line">&gt; 按照 node 数量 自动伸缩 dns 数量</span><br></pre></td></tr></table></figure>
<p>vi dns-auto-scaling.yaml</p>
<p>kind: ServiceAccount<br>
apiVersion: v1<br>
metadata:<br>
name: kube-dns-autoscaler<br>
namespace: kube-system<br>
labels:<br>
<a href="http://addonmanager.kubernetes.io/mode:" target="_blank" rel="noopener">addonmanager.kubernetes.io/mode:</a> Reconcile</p>
<hr>
<p>kind: ClusterRole<br>
apiVersion: <a href="http://rbac.authorization.k8s.io/v1" target="_blank" rel="noopener">rbac.authorization.k8s.io/v1</a><br>
metadata:<br>
name: system:kube-dns-autoscaler<br>
labels:<br>
<a href="http://addonmanager.kubernetes.io/mode:" target="_blank" rel="noopener">addonmanager.kubernetes.io/mode:</a> Reconcile<br>
rules:</p>
<ul>
<li>apiGroups: [&quot;&quot;]<br>
resources: [“nodes”]<br>
verbs: [“list”]</li>
<li>apiGroups: [&quot;&quot;]<br>
resources: [“replicationcontrollers/scale”]<br>
verbs: [“get”, “update”]</li>
<li>apiGroups: [“extensions”]<br>
resources: [“deployments/scale”, “replicasets/scale”]<br>
verbs: [“get”, “update”]</li>
<li>apiGroups: [&quot;&quot;]<br>
resources: [“configmaps”]<br>
verbs: [“get”, “create”]</li>
</ul>
<hr>
<p>kind: ClusterRoleBinding<br>
apiVersion: <a href="http://rbac.authorization.k8s.io/v1" target="_blank" rel="noopener">rbac.authorization.k8s.io/v1</a><br>
metadata:<br>
name: system:kube-dns-autoscaler<br>
labels:<br>
<a href="http://addonmanager.kubernetes.io/mode:" target="_blank" rel="noopener">addonmanager.kubernetes.io/mode:</a> Reconcile<br>
subjects:</p>
<ul>
<li>kind: ServiceAccount<br>
name: kube-dns-autoscaler<br>
namespace: kube-system<br>
roleRef:<br>
kind: ClusterRole<br>
name: system:kube-dns-autoscaler<br>
apiGroup: <a href="http://rbac.authorization.k8s.io" target="_blank" rel="noopener">rbac.authorization.k8s.io</a></li>
</ul>
<hr>
<p>apiVersion: apps/v1<br>
kind: Deployment<br>
metadata:<br>
name: kube-dns-autoscaler<br>
namespace: kube-system<br>
labels:<br>
k8s-app: kube-dns-autoscaler<br>
<a href="http://kubernetes.io/cluster-service:" target="_blank" rel="noopener">kubernetes.io/cluster-service:</a> &quot;true&quot;<br>
<a href="http://addonmanager.kubernetes.io/mode:" target="_blank" rel="noopener">addonmanager.kubernetes.io/mode:</a> Reconcile<br>
spec:<br>
selector:<br>
matchLabels:<br>
k8s-app: kube-dns-autoscaler<br>
template:<br>
metadata:<br>
labels:<br>
k8s-app: kube-dns-autoscaler<br>
annotations:<br>
<a href="http://scheduler.alpha.kubernetes.io/critical-pod:" target="_blank" rel="noopener">scheduler.alpha.kubernetes.io/critical-pod:</a> ''<br>
spec:<br>
priorityClassName: system-cluster-critical<br>
containers:<br>
- name: autoscaler<br>
image: jicki/cluster-proportional-autoscaler-amd64:1.1.2-r2<br>
resources:<br>
requests:<br>
cpu: &quot;20m&quot;<br>
memory: &quot;10Mi&quot;<br>
command:<br>
- /cluster-proportional-autoscaler<br>
- --namespace=kube-system<br>
- --configmap=kube-dns-autoscaler<br>
- --target=Deployment/coredns<br>
- --default-params={“linear”:{“coresPerReplica”:256,“nodesPerReplica”:16,“preventSinglePointFailure”:true}}<br>
- --logtostderr=true<br>
- --v=2<br>
tolerations:<br>
- key: &quot;CriticalAddonsOnly&quot;<br>
operator: &quot;Exists&quot;<br>
serviceAccountName: kube-dns-autoscaler</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="导入文件">导入文件</span></h1>
<p>[root@kubernetes-64 coredns]# kubectl apply -f dns-auto-scaling.yaml<br>
serviceaccount/kube-dns-autoscaler created<br>
<a href="http://clusterrole.rbac.authorization.k8s.io/system:kube-dns-autoscaler" target="_blank" rel="noopener">clusterrole.rbac.authorization.k8s.io/system:kube-dns-autoscaler</a> created<br>
<a href="http://clusterrolebinding.rbac.authorization.k8s.io/system:kube-dns-autoscaler" target="_blank" rel="noopener">clusterrolebinding.rbac.authorization.k8s.io/system:kube-dns-autoscaler</a> created<br>
deployment.apps/kube-dns-autoscaler created</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 部署 Dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&gt; 官方 dashboard 的github https://github.com/kubernetes/dashboard</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">### 下载 dashboard 镜像</span><br></pre></td></tr></table></figure>
<h1><span id="官方镜像">官方镜像</span></h1>
<p><a href="http://k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0" target="_blank" rel="noopener">k8s.gcr.io/kubernetes-dashboard-amd64:v1.10.0</a></p>
<h1><span id="个人的镜像">个人的镜像</span></h1>
<p>jicki/kubernetes-dashboard-amd64:v1.10.0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 下载 yaml 文件</span><br></pre></td></tr></table></figure>
<p>curl -O <a href="https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/dashboard/master/src/deploy/recommended/kubernetes-dashboard.yaml</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line">### 导入 yaml</span><br></pre></td></tr></table></figure>
<h1><span id="替换所有的-images">替换所有的 images</span></h1>
<p>sed -i ‘s/k8s.gcr.io/jicki/g’ *</p>
<h1><span id="导入文件">导入文件</span></h1>
<p>[root@kubernetes-64 dashboard]# kubectl apply -f kubernetes-dashboard.yaml<br>
secret “kubernetes-dashboard-certs” created<br>
serviceaccount “kubernetes-dashboard” created<br>
role “kubernetes-dashboard-minimal” created<br>
rolebinding “kubernetes-dashboard-minimal” created<br>
deployment “kubernetes-dashboard” created<br>
service “kubernetes-dashboard” created</p>
<p>[root@kubernetes-64 ~]# kubectl get pods,svc -n kube-system<br>
NAME                                       READY     STATUS    RESTARTS   AGE<br>
po/coredns-5984fb8cbb-77dl4                1/1       Running   0          3h<br>
po/coredns-5984fb8cbb-9hdwt                1/1       Running   0          3h<br>
po/kubernetes-dashboard-78bcdc4d64-x6fhq   1/1       Running   0          14s</p>
<p>NAME                       TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE<br>
svc/kube-dns               ClusterIP   10.254.0.2      <none>        53/UDP,53/TCP   3h<br>
svc/kubernetes-dashboard   ClusterIP   10.254.18.143   <none>        443/TCP         14s</none></none></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 部署 Ingress</span><br><span class="line"></span><br><span class="line">&gt; Kubernetes 暴露服务的方式目前只有三种：LoadBlancer Service、NodePort Service、Ingress； 什么是 Ingress ? Ingress 就是利用 Nginx Haproxy 等负载均衡工具来暴露 Kubernetes 服务。</span><br><span class="line">&gt;</span><br><span class="line">&gt;</span><br><span class="line">&gt; 官方地址  https://kubernetes.github.io/ingress-nginx/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 配置 调度 node</span><br></pre></td></tr></table></figure>
<h1><span id="ingress-有多种方式-1-deployment-自由调度-replicas">ingress 有多种方式 1.  deployment 自由调度 replicas</span></h1>
<pre><code>                 2.  daemonset 全局调度 分配到所有node里
</code></pre>
<h1><span id="deployment-自由调度过程中由于我们需要-约束-controller-调度到指定的-node-中所以需要对-node-进行-label-标签">deployment 自由调度过程中，由于我们需要 约束 controller 调度到指定的 node 中，所以需要对 node 进行 label 标签</span></h1>
<h1><span id="默认如下">默认如下:</span></h1>
<p>[root@kubernetes-64 ingress]# kubectl get nodes<br>
NAME            STATUS    ROLES     AGE       VERSION<br>
kubernetes-64   Ready     master    1d        v1.13.1<br>
kubernetes-65   Ready     master    1d        v1.13.1<br>
kubernetes-66   Ready     node      1d        v1.13.1</p>
<h1><span id="对-65-与-66-打上-label">对 65 与 66 打上 label</span></h1>
<p>[root@kubernetes-64 ingress]# kubectl label nodes kubernetes-65 ingress=proxy<br>
node “kubernetes-65” labeled<br>
[root@kubernetes-64 ingress]# kubectl label nodes kubernetes-66 ingress=proxy<br>
node “kubernetes-66” labeled</p>
<h1><span id="打完标签以后">打完标签以后</span></h1>
<p>[root@kubernetes-64 ingress]# kubectl get nodes --show-labels<br>
NAME            STATUS                     ROLES     AGE       VERSION   LABELS<br>
kubernetes-64   Ready,SchedulingDisabled   <none>    32m       v1.13.1   <a href="http://beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=kubernetes-64" target="_blank" rel="noopener">beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,kubernetes.io/hostname=kubernetes-64</a><br>
kubernetes-65   Ready                      <none>    17m       v1.13.1   <a href="http://beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,ingress=proxy,kubernetes.io/hostname=kubernetes-65" target="_blank" rel="noopener">beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,ingress=proxy,kubernetes.io/hostname=kubernetes-65</a><br>
kubernetes-66   Ready                      <none>    4m        v1.13.1   <a href="http://beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,ingress=proxy,kubernetes.io/hostname=kubernetes-66" target="_blank" rel="noopener">beta.kubernetes.io/arch=amd64,beta.kubernetes.io/os=linux,ingress=proxy,kubernetes.io/hostname=kubernetes-66</a></none></none></none></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="下载镜像">下载镜像</span></h1>
<h1><span id="官方镜像">官方镜像</span></h1>
<p><a href="http://quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.21.0" target="_blank" rel="noopener">quay.io/kubernetes-ingress-controller/nginx-ingress-controller:0.21.0</a></p>
<h1><span id="国内镜像">国内镜像</span></h1>
<p>jicki/nginx-ingress-controller:0.21.0</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="下载-yaml-文件">下载 yaml 文件</span></h1>
<p>wget <a href="https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml" target="_blank" rel="noopener">https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/deploy/mandatory.yaml</a></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="替换所有的-images">替换所有的 images</span></h1>
<p>sed -i ‘s/quay.io/kubernetes-ingress-controller/jicki/g’ *</p>
<h1><span id="上面-对-两个-node-打了-label-所以配置-replicas-2">上面 对 两个 node 打了 label 所以配置 replicas: 2</span></h1>
<h1><span id="修改-yaml-文件-增加-rbac-认证-hostnetwork-还有-nodeselector-第二个-spec-下-增加">修改 yaml 文件 增加 rbac 认证 , hostNetwork  还有 nodeSelector, 第二个 spec 下 增加。</span></h1>
<p>vi mandatory.yaml</p>
<p>spec:<br>
replicas: 2<br>
…<br>
spec:<br>
serviceAccountName: nginx-ingress-serviceaccount<br>
hostNetwork: true<br>
nodeSelector:<br>
ingress: proxy<br>
…</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="导入-yaml-文件">导入 yaml 文件</span></h1>
<p>[root@kubernetes-64 nginx-ingress]# kubectl apply -f mandatory.yaml<br>
namespace/ingress-nginx created<br>
configmap/nginx-configuration created<br>
configmap/tcp-services created<br>
configmap/udp-services created<br>
serviceaccount/nginx-ingress-serviceaccount created<br>
<a href="http://clusterrole.rbac.authorization.k8s.io/nginx-ingress-clusterrole" target="_blank" rel="noopener">clusterrole.rbac.authorization.k8s.io/nginx-ingress-clusterrole</a> created<br>
<a href="http://role.rbac.authorization.k8s.io/nginx-ingress-role" target="_blank" rel="noopener">role.rbac.authorization.k8s.io/nginx-ingress-role</a> created<br>
<a href="http://rolebinding.rbac.authorization.k8s.io/nginx-ingress-role-nisa-binding" target="_blank" rel="noopener">rolebinding.rbac.authorization.k8s.io/nginx-ingress-role-nisa-binding</a> created<br>
<a href="http://clusterrolebinding.rbac.authorization.k8s.io/nginx-ingress-clusterrole-nisa-binding" target="_blank" rel="noopener">clusterrolebinding.rbac.authorization.k8s.io/nginx-ingress-clusterrole-nisa-binding</a> created<br>
deployment.extensions/nginx-ingress-controller created</p>
<h1><span id="查看服务可以看到这两个-pods-被分别调度到-65-与-66-中">查看服务，可以看到这两个 pods 被分别调度到 65 与 66 中</span></h1>
<p>[root@kubernetes-64 ingress]# kubectl get pods -n ingress-nginx -o wide<br>
NAME                                        READY     STATUS    RESTARTS   AGE       IP             NODE<br>
nginx-ingress-controller-8476958f94-8fh5h   1/1       Running   0          5m        172.16.1.66    kubernetes-66<br>
nginx-ingress-controller-8476958f94-qfhhp   1/1       Running   0          5m        172.16.1.65    kubernetes-65</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="查看我们原有的-svc">查看我们原有的 svc</span></h1>
<p>[root@kubernetes-64 ingress]# kubectl get pods<br>
NAME                        READY     STATUS    RESTARTS   AGE<br>
alpine                      1/1       Running   0          24m<br>
nginx-dm-84f8f49555-tmqzm   1/1       Running   0          24m<br>
nginx-dm-84f8f49555-wdk67   1/1       Running   0          24m</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="创建一个-基于-nginx-dm-的-ingress">创建一个 基于 nginx-dm 的 ingress</span></h1>
<p>vi nginx-ingress.yaml</p>
<p>apiVersion: extensions/v1beta1<br>
kind: Ingress<br>
metadata:<br>
name: nginx-ingress<br>
spec:<br>
rules:</p>
<ul>
<li>host: <a href="http://nginx.jicki.me" target="_blank" rel="noopener">nginx.jicki.me</a><br>
http:<br>
paths:
<ul>
<li>backend:<br>
serviceName: nginx-svc<br>
servicePort: 80</li>
</ul>
</li>
</ul>
<h1><span id="查看服务">查看服务</span></h1>
<p>[root@kubernetes-64 ingress]# kubectl get ingress<br>
NAME            HOSTS            ADDRESS   PORTS     AGE<br>
nginx-ingress   <a href="http://nginx.jicki.me" target="_blank" rel="noopener">nginx.jicki.me</a>             80        6s</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="测试访问">测试访问</span></h1>
<p>[root@kubernetes-64 ingress]# curl <a href="http://nginx.jicki.me" target="_blank" rel="noopener">nginx.jicki.me</a></p>
<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
<title>Welcome to nginx!</title>
<style>
    body {
        width: 35em;
        margin: 0 auto;
        font-family: Tahoma, Verdana, Arial, sans-serif;
    }
</style>
</head>
<body>
<h1><span id="welcome-to-nginx">Welcome to nginx!</span></h1>
<p>If you see this page, the nginx web server is successfully installed and
working. Further configuration is required.</p>
<p>For online documentation and support please refer to
<a href="http://nginx.org/" target="_blank" rel="noopener">nginx.org</a>.<br>
Commercial support is available at
<a href="http://nginx.com/" target="_blank" rel="noopener">nginx.com</a>.</p>
<p><em>Thank you for using nginx.</em></p>
</body>
</html>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="配置一个基于域名的-https-ingress">配置一个基于域名的 https , ingress</span></h1>
<h1><span id="创建一个-基于-自身域名的-证书">创建一个 基于 自身域名的 证书</span></h1>
<p>openssl req -x509 -nodes -days 3650 -newkey rsa:2048 -keyout dashboard.jicki.me-key.key -out dashboard.jicki.me.pem -subj “/CN=<a href="http://dashboard.jicki.me" target="_blank" rel="noopener">dashboard.jicki.me</a>”</p>
<h1><span id="导入-域名的证书-到-集群-的-secret-中">导入 域名的证书 到 集群 的 secret 中</span></h1>
<p>kubectl create secret tls dashboard-secret --namespace=kube-system --cert dashboard.jicki.me.pem --key dashboard.jicki.me-key.key</p>
<h1><span id="查看-secret">查看 secret</span></h1>
<p>[root@kubernetes-64 dashboard]# kubectl get secret -n kube-system<br>
NAME                                     TYPE                                  DATA      AGE<br>
dashboard-secret                         <a href="http://kubernetes.io/tls" target="_blank" rel="noopener">kubernetes.io/tls</a>                     2         1m</p>
<h1><span id="创建一个-ingress">创建一个 ingress</span></h1>
<p>vi dashboard-ingress.yaml</p>
<p>apiVersion: extensions/v1beta1<br>
kind: Ingress<br>
metadata:<br>
name: kubernetes-dashboard<br>
namespace: kube-system<br>
annotations:<br>
<a href="http://ingress.kubernetes.io/ssl-passthrough:" target="_blank" rel="noopener">ingress.kubernetes.io/ssl-passthrough:</a> &quot;true&quot;<br>
<a href="http://nginx.ingress.kubernetes.io/secure-backends:" target="_blank" rel="noopener">nginx.ingress.kubernetes.io/secure-backends:</a> &quot;true&quot;<br>
spec:<br>
tls:</p>
<ul>
<li>hosts:
<ul>
<li><a href="http://dashboard.jicki.me" target="_blank" rel="noopener">dashboard.jicki.me</a><br>
secretName: dashboard-secret<br>
rules:</li>
</ul>
</li>
<li>host: <a href="http://dashboard.jicki.me" target="_blank" rel="noopener">dashboard.jicki.me</a><br>
http:<br>
paths:
<ul>
<li>path: /<br>
backend:<br>
serviceName: kubernetes-dashboard<br>
servicePort: 443</li>
</ul>
</li>
</ul>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="测试访问">测试访问</span></h1>
<p>[root@kubernetes-64 dashboard]# curl -I -k <a href="https://dashboard.jicki.me" target="_blank" rel="noopener">https://dashboard.jicki.me</a><br>
HTTP/1.1 200 OK<br>
Server: nginx/1.13.12<br>
Date: Wed, 11 Jul 2018 07:19:03 GMT<br>
Content-Type: text/html; charset=utf-8<br>
Content-Length: 990<br>
Connection: keep-alive<br>
Vary: Accept-Encoding<br>
Accept-Ranges: bytes<br>
Cache-Control: no-store<br>
Last-Modified: Tue, 13 Feb 2018 11:17:03 GMT<br>
Strict-Transport-Security: max-age=15724800; includeSubDomains</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1><span id="登录认证">登录认证</span></h1>
<h1><span id="首先创建一个-dashboard-rbac-超级用户">首先创建一个 dashboard rbac 超级用户</span></h1>
<p>vi dashboard-admin-rbac.yaml</p>
<hr>
<p>apiVersion: v1<br>
kind: ServiceAccount<br>
metadata:<br>
labels:<br>
k8s-app: kubernetes-dashboard<br>
name: kubernetes-dashboard-admin<br>
namespace: kube-system</p>
<hr>
<p>apiVersion: <a href="http://rbac.authorization.k8s.io/v1" target="_blank" rel="noopener">rbac.authorization.k8s.io/v1</a><br>
kind: ClusterRoleBinding<br>
metadata:<br>
name: kubernetes-dashboard-admin<br>
labels:<br>
k8s-app: kubernetes-dashboard<br>
roleRef:<br>
apiGroup: <a href="http://rbac.authorization.k8s.io" target="_blank" rel="noopener">rbac.authorization.k8s.io</a><br>
kind: ClusterRole<br>
name: cluster-admin<br>
subjects:</p>
<ul>
<li>kind: ServiceAccount<br>
name: kubernetes-dashboard-admin<br>
namespace: kube-system</li>
</ul>
<h1><span id="导入文件">导入文件</span></h1>
<p>[root@kubernetes-64 dashboard]# kubectl apply -f dashboard-admin-rbac.yaml<br>
serviceaccount “kubernetes-dashboard-admin” created<br>
clusterrolebinding “kubernetes-dashboard-admin” created</p>
<h1><span id="查看超级用户的-token-名称">查看超级用户的 token 名称</span></h1>
<p>[root@kubernetes-64 dashboard]# kubectl -n kube-system get secret | grep kubernetes-dashboard-admin<br>
kubernetes-dashboard-admin-token-mnhdz   <a href="http://kubernetes.io/service-account-token" target="_blank" rel="noopener">kubernetes.io/service-account-token</a>   3         1m</p>
<h1><span id="查看-token-部分">查看 token 部分</span></h1>
<p>[root@kubernetes-64 dashboard]# kubectl describe -n kube-system secret/kubernetes-dashboard-admin-token-mnhdz<br>
Name:         kubernetes-dashboard-admin-token-mnhdz<br>
Namespace:    kube-system<br>
Labels:       <none><br>
Annotations:  <a href="http://kubernetes.io/service-account.name=kubernetes-dashboard-admin" target="_blank" rel="noopener">kubernetes.io/service-account.name=kubernetes-dashboard-admin</a><br>
<a href="http://kubernetes.io/service-account.uid=dc14511d-0020-11e8-b47b-44a8420b9988" target="_blank" rel="noopener">kubernetes.io/service-account.uid=dc14511d-0020-11e8-b47b-44a8420b9988</a></none></p>
<p>Type:  <a href="http://kubernetes.io/service-account-token" target="_blank" rel="noopener">kubernetes.io/service-account-token</a></p>
<h1><span id="data">Data</span></h1>
<p>ca.crt:     1363 bytes<br>
namespace:  11 bytes<br>
token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbi10b2tlbi1tbmhkeiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImRjMTQ1MTFkLTAwMjAtMTFlOC1iNDdiLTQ0YTg0MjBiOTk4OCIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlcm5ldGVzLWRhc2hib2FyZC1hZG1pbiJ9.Vg7vYBIaBICYFCX_XORvoUjkYAKdQoAuT2sy8o4y8Z6DmMaCQXijOBGCWsS40-n_qiBhlrSwLeN0RvjCOfLmcH4gUSjPBkSmc-S6SHh09ErzrHjCQSblCCZgXjyyse2w1LwWw87CiAiwHCb0Jm7r0lhm4DjhXeLpUhdXoqOltHlBoJqxzDwb9qKgtY-nsQ2Y9dhV405GeqB9RLOxSKHWx6K1lXP_0tLUGgIatJx6f-EMurFbmODJfex9mT2LTq9pblblegw9EG9j2IhfHQSnwR8hPMT3Tku-XEf3vtV-1eFqetZHRJHS23machhvSvuppFjmPAd_ID3eETBt7ncNmQ</p>
<h1><span id="登录-web-ui-选择-令牌登录">登录 web ui 选择 令牌登录</span></h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">![ dashboard ][3]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 部署 monitoring</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># k8s 运维相关</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 基础维护</span><br></pre></td></tr></table></figure>
<h1><span id="当需要对主机进行维护升级时首先将节点主机设置成不可调度模式">当需要对主机进行维护升级时，首先将节点主机设置成不可调度模式：</span></h1>
<p>kubectl cordon［nodeid］</p>
<h1><span id="然后需要将主机上正在运行的容器驱赶到其它可用节点">然后需要将主机上正在运行的容器驱赶到其它可用节点：</span></h1>
<p>kubectl drain ［nodeid］</p>
<h1><span id="给予900秒宽限期优雅的调度">给予900秒宽限期优雅的调度</span></h1>
<p>kubectl drain node1.k8s.novalocal --grace-period=120</p>
<h1><span id="当容器迁移完毕后运维人员可以对该主机进行操作配置升级性能参数调优等等-当对主机的维护操作完毕后-再将主机设置成可调度模式">当容器迁移完毕后，运维人员可以对该主机进行操作，配置升级性能参数调优等等。当对主机的维护操作完毕后， 再将主机设置成可调度模式：</span></h1>
<p>kubectl uncordon [nodeid]</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># Other</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 特殊 env</span><br></pre></td></tr></table></figure>
<h1><span id="yaml-中的一些-特殊-env">yaml 中的一些 特殊 env</span></h1>
<pre><code>env:
- name: MY_POD_NAME
  valueFrom:
    fieldRef:
      fieldPath: metadata.name
- name: MY_POD_NAMESPACE
  valueFrom:
    fieldRef:
      fieldPath: metadata.namespace
- name: MY_POD_IP
  valueFrom:
    fieldRef:
      fieldPath: status.podIP
</code></pre>
<pre><code>

  [1]: https://jicki.me/img/posts/kubernetes/dashboard.png
  [2]: https://jicki.me/img/posts/kubernetes/hamaster.jpg
  [3]: https://jicki.me/img/posts/kubernetes/dashboard-new.jpeg


</code></pre>

                

                <hr>
                <!-- Pager -->
                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/2019/01/30/2018-10-09-kubernetes-1.12.1/" data-toggle="tooltip" data-placement="top" title="kubernetes 1.12.1">&larr; Previous Post</a>
                        </li>
                    
                    
                        <li class="next">
                            <a href="/2019/01/30/template/" data-toggle="tooltip" data-placement="top" title="template page">Next Post &rarr;</a>
                        </li>
                    
                </ul>

                <br>

                <!--打赏-->
                
                <!--打赏-->

                <br>
                <!--分享-->
                
                    <div class="social-share"  data-wechat-qrcode-helper="" align="center"></div>
                    <!--  css & js -->
                    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/css/share.min.css">
                    <script src="https://cdnjs.cloudflare.com/ajax/libs/social-share.js/1.0.16/js/social-share.min.js"></script>
                
                <!--分享-->
                <br>                       
                
                <!-- require APlayer -->
                

                <!-- duoshuo Share start -->
                
                <!-- 多说 Share end-->

                <!-- 多说评论框 start -->
                
                <!-- 多说评论框 end -->

                <!-- disqus comment start -->
                
                    <div class="comment">
                        <div id="disqus_thread" class="disqus-thread"></div>
                    </div>
                
                <!-- disqus comment end -->

                

            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>FRIENDS</h5>
                <ul class="list-inline">

                    
                        <li><a href="https://www.jicki.me" target="_blank">小炒肉</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>




<!-- disqus embedded js code start (one page only need to embed once) -->
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = "jicki";
    var disqus_identifier = "https://www.jicki.me/2019/01/30/2018-12-19-kubernetes-1.13.1/";
    var disqus_url = "https://www.jicki.me/2019/01/30/2018-12-19-kubernetes-1.13.1/";

    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<!-- disqus embedded js code start end -->





<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>
<style>
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                    <li>
                        <a target="_blank" href="https://twitter.com/jicki234">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                
                
                    <li>
                        <a target="_blank" href="https://www.zhihu.com/people/jicki">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa  fa-stack-1x fa-inverse">知</i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="http://weibo.com/jicki520">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-weibo fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.facebook.com/jicki">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://github.com/jicki">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank" href="https://www.linkedin.com/in/jicki">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                </ul>
                <p class="copyright text-muted">
                    Copyright &copy; 小炒肉 2019 
                    <br>
                    Theme by <a href="http://beantech.org">BeanTech</a> 
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    re-Ported by <a href="http://www.huweihuang.com">胡伟煌</a> | 
                    <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" width="91px" height="20px" src="https://ghbtns.com/github-btn.html?user=huweihuang&repo=hexo-theme-huweihuang&type=star&count=true">
                    </iframe>
                </p>
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->
<script src="/js/jquery.min.js"></script>

<!-- Bootstrap Core JavaScript -->
<script src="/js/bootstrap.min.js"></script>

<!-- Custom Theme JavaScript -->
<script src="/js/hux-blog.min.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://www.jicki.me/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-85602329-1';
    var _gaDomain = 'jicki.me';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->

<script>
    // dynamic User by Hux
    var _baId = '1b38b88e4559c6725330b8c3328e2de3';

    // Originial
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?" + _baId;
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
</script>






	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>
<!-- Image to hack wechat -->
<img src="https://www.jicki.me/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
